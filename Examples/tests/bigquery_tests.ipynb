{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import datetime\n",
    "import sqlite3\n",
    "\n",
    "from google.cloud import bigquery\n",
    "\n",
    "import data_algebra\n",
    "import data_algebra.test_util\n",
    "from data_algebra.data_ops import *\n",
    "import data_algebra.BigQuery\n",
    "import data_algebra.SQLite\n",
    "\n",
    "import pytest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# set up big query client\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/Users/johnmount/big_query/big_query_jm.json\"\n",
    "# os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]  # trigger key error if not present\n",
    "bq_client = bigquery.Client()\n",
    "\n",
    "bq_handle = data_algebra.BigQuery.BigQueryModel().db_handle(bq_client)\n",
    "data_catalog = 'data-algebra-test'\n",
    "data_schema = 'test_1'\n",
    "\n",
    "# set up sqlite client\n",
    "conn_sqlite = sqlite3.connect(\":memory:\")\n",
    "db_model_sqlite = data_algebra.SQLite.SQLiteModel()\n",
    "db_model_sqlite.prepare_connection(conn_sqlite)\n",
    "db_handle_sqlite = db_model_sqlite.db_handle(conn_sqlite)\n",
    "\n",
    "db_handles = [bq_handle, db_handle_sqlite]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT `group`,\n",
      "       `val`\n",
      "FROM `data-algebra-test.test_1.pytest_temp_z`\n"
     ]
    }
   ],
   "source": [
    "# test prefixing table ops\n",
    "\n",
    "bq_handle_prefixed = data_algebra.BigQuery.BigQueryModel(\n",
    "    table_prefix=f'{data_catalog}.{data_schema}'\n",
    "    ).db_handle(bq_client)  # don't close, sharing connection\n",
    "\n",
    "d = data_algebra.default_data_model.pd.DataFrame({\n",
    "    'group': ['a', 'a', 'b', 'b'],\n",
    "    'val': [1, 2, 3, 4],\n",
    "})\n",
    "table_name = 'pytest_temp_z'\n",
    "\n",
    "descr = bq_handle_prefixed.insert_table(d, table_name=table_name, allow_overwrite=True)\n",
    "\n",
    "bq_handle_prefixed.drop_table(table_name)\n",
    "\n",
    "print(bq_handle_prefixed.to_sql(descr, pretty=True))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def test_bigquery_1():\n",
    "    d = data_algebra.default_data_model.pd.DataFrame({\n",
    "        'group': ['a', 'a', 'b', 'b'],\n",
    "        'val': [1, 2, 3, 4],\n",
    "    })\n",
    "    table_name = f'{data_catalog}.{data_schema}.pytest_temp_d'\n",
    "\n",
    "    # this is the pattern BigQuery needs to compute\n",
    "    # median, window function then a pseudo-aggregation\n",
    "    # NOTE: sqllite doesn't allow median as a window function,\n",
    "    # meaning it can not run this query.\n",
    "    ops = describe_table(d, table_name=table_name). \\\n",
    "        extend(\n",
    "            {'med_val': 'median(val)'},\n",
    "            partition_by=['group']). \\\n",
    "        project(\n",
    "            {'med_val': 'mean(med_val)'},  # pseudo-aggregator\n",
    "            group_by=['group'])\n",
    "\n",
    "    expect = data_algebra.default_data_model.pd.DataFrame({\n",
    "        'group': ['a', 'b'],\n",
    "        'med_val': [1.5, 3.5],\n",
    "    })\n",
    "\n",
    "    data_algebra.test_util.check_transform_on_handles(\n",
    "        ops=ops,\n",
    "        data=d,\n",
    "        expect=expect,\n",
    "        db_handles=[bq_handle],\n",
    "        check_parse=False,\n",
    "    )\n",
    "\n",
    "\n",
    "test_bigquery_1()\n",
    "\n",
    "\n",
    "def test_bigquery_2():\n",
    "    d = data_algebra.default_data_model.pd.DataFrame({\n",
    "        'group': ['a', 'a', 'a', 'b', 'b'],\n",
    "        'v1': [1, 2, 2, 0, 0],\n",
    "        'v2': [1, 2, 3, 4, 5],\n",
    "    })\n",
    "    table_name = f'{data_catalog}.{data_schema}.pytest_temp_d'\n",
    "\n",
    "    # this is the pattern BigQuery needs to compute\n",
    "    # median, window function then a pseudo-aggregation\n",
    "    # refs on BigQuery window fn horseshit:\n",
    "    #  https://iamhectorotero.github.io/median-and-group-by/\n",
    "    #  https://chartio.com/resources/tutorials/how-countdistinct-field-works-in-google-bigquery/\n",
    "    ops = describe_table(d, table_name=table_name). \\\n",
    "        extend({\n",
    "            'med_1': 'v1.median()',  # median is only a window fn in Big Query\n",
    "            'med_2': 'v2.median()',  # median is only a window fn in Big Query\n",
    "            },\n",
    "            partition_by=['group']). \\\n",
    "        project({\n",
    "            'med_1': 'med_1.mean()',  # pseudo aggregator\n",
    "            'med_2': 'med_2.mean()',  # pseudo aggregator\n",
    "            'mean_1': 'v1.mean()',\n",
    "            'mean_2': 'v2.mean()',\n",
    "            'nu_1': 'v1.nunique()',\n",
    "            'nu_2': 'v2.nunique()',\n",
    "            },\n",
    "            group_by=['group'])\n",
    "\n",
    "    expect = data_algebra.default_data_model.pd.DataFrame({\n",
    "        'group': ['a', 'b'],\n",
    "        'med_1': [2, 0],\n",
    "        'med_2': [2.0, 4.5],\n",
    "        'mean_1': [1.66666666667, 0.0],\n",
    "        'mean_2': [2.0, 4.5],\n",
    "        'nu_1': [2, 1],\n",
    "        'nu_2': [3, 2],\n",
    "    })\n",
    "\n",
    "    data_algebra.test_util.check_transform_on_handles(\n",
    "        ops=ops,\n",
    "        data=d,\n",
    "        expect=expect,\n",
    "        db_handles=[bq_handle],\n",
    "        check_parse=False,\n",
    "    )\n",
    "\n",
    "\n",
    "test_bigquery_2()\n",
    "\n",
    "\n",
    "def test_bigquery_insert_raise():\n",
    "    d = data_algebra.default_data_model.pd.DataFrame({\n",
    "        'group': ['a', 'a', 'a', 'b', 'b'],\n",
    "        'v1': [1, 2, 2, 0, 0],\n",
    "        'v2': [1, 2, 3, 4, 5]})\n",
    "    table_name = f'{data_catalog}.{data_schema}.pytest_temp_dx'\n",
    "    bq_handle.drop_table(table_name)\n",
    "    bq_handle.insert_table(d, table_name=table_name, allow_overwrite=True)\n",
    "    with pytest.raises(ValueError):\n",
    "        bq_handle.insert_table(d, table_name=table_name, allow_overwrite=False)\n",
    "    bq_handle.drop_table(table_name)\n",
    "\n",
    "\n",
    "test_bigquery_insert_raise()\n",
    "\n",
    "\n",
    "def test_bigquery_date_1():\n",
    "    d = data_algebra.default_data_model.pd.DataFrame({\n",
    "        'group': ['a', 'a', 'a', 'b', 'b'],\n",
    "        'v1': [1, 2, 2, 0, 0],\n",
    "        'v2': [1, 2, 3, 4, 5],\n",
    "        'dt': data_algebra.default_data_model.pd.to_datetime([1490195805, 1490195815, 1490295805, 1490196805, 1490195835], unit='s')\n",
    "    })\n",
    "    d['dt_str'] = d.dt.astype(str)\n",
    "\n",
    "    table_name = f'{data_catalog}.{data_schema}.pytest_temp_d'\n",
    "\n",
    "    ops = describe_table(d, table_name=table_name) .\\\n",
    "        extend({\n",
    "            'date': bq_handle.fns.datetime_to_date('dt'),\n",
    "            'date_str': bq_handle.fns.trimstr('dt_str', start=0, stop=10),\n",
    "         }) . \\\n",
    "        extend({\n",
    "            'mean_v1': 'v1.mean()',\n",
    "            'count': '_size()',\n",
    "            },\n",
    "            partition_by='group') . \\\n",
    "        drop_columns(['dt'])  # date will comback with UTC and other alterations\n",
    "\n",
    "    expect = d.copy()\n",
    "    expect['date'] = expect.dt.dt.date.copy()\n",
    "    expect['date_str'] = expect.dt_str.str.slice(start=0, stop=10)\n",
    "    expect['mean_v1'] = [5/3, 5/3, 5/3, 0, 0]\n",
    "    expect['count'] = [3, 3, 3, 2, 2]\n",
    "    del expect['dt']\n",
    "\n",
    "    # res_pandas = ops.transform(d)\n",
    "    # bq_handle.insert_table(d, table_name=table_name, allow_overwrite=True)\n",
    "    # res_bq = bq_handle.read_query(ops)\n",
    "    # assert data_algebra.test_util.equivalent_frames(expect, res_pandas)\n",
    "    # assert data_algebra.test_util.equivalent_frames(expect, res_bq)\n",
    "\n",
    "    data_algebra.test_util.check_transform_on_handles(\n",
    "        ops=ops,\n",
    "        data=d,\n",
    "        expect=expect,\n",
    "        db_handles=[bq_handle],\n",
    "        check_parse=False,\n",
    "    )\n",
    "\n",
    "\n",
    "test_bigquery_date_1()\n",
    "\n",
    "\n",
    "def test_big_query_and():\n",
    "    d = data_algebra.default_data_model.pd.DataFrame({\n",
    "        'group': ['a', 'a', 'a', 'b', 'b'],\n",
    "        'v1': [1, 2, 2, 0, 2],\n",
    "        'v2': [1, 2, 3, 4, 5],\n",
    "    })\n",
    "    table_name = f'{data_catalog}.{data_schema}.pytest_temp_d'\n",
    "\n",
    "    # build a description that looks like the BigQuery db handle built it.\n",
    "    ops = describe_table(d, table_name=table_name) .\\\n",
    "        select_rows(\"(group == 'a') & (v1 == 2)\")\n",
    "\n",
    "    # see & gets translated to AND\n",
    "    sql = bq_handle.to_sql(ops)\n",
    "    assert sql.find('&') < 0\n",
    "    assert sql.find('AND') > 0\n",
    "\n",
    "    expect = data_algebra.default_data_model.pd.DataFrame({\n",
    "        'group': ['a', 'a'],\n",
    "        'v1': [2, 2],\n",
    "        'v2': [2, 3],\n",
    "    })\n",
    "\n",
    "    data_algebra.test_util.check_transform_on_handles(\n",
    "        ops=ops,\n",
    "        data=d,\n",
    "        expect=expect,\n",
    "        db_handles=db_handles,\n",
    "        check_parse=False,\n",
    "    )\n",
    "\n",
    "\n",
    "test_big_query_and()\n",
    "\n",
    "\n",
    "def test_big_query_notor():\n",
    "    d = data_algebra.default_data_model.pd.DataFrame({\n",
    "        'group': ['a', 'a', 'a', 'b', 'b'],\n",
    "        'v1': [1, 2, 2, 0, 2],\n",
    "        'v2': [1, 2, 3, 4, 5],\n",
    "    })\n",
    "    table_name = f'{data_catalog}.{data_schema}.pytest_temp_d'\n",
    "\n",
    "    # build a description that looks like the BigQuery db handle built it.\n",
    "    ops = describe_table(d, table_name=table_name) .\\\n",
    "        select_rows(\"not ((group == 'a') or (v1 == 2))\")\n",
    "\n",
    "    # see & gets translated to AND\n",
    "    sql = bq_handle.to_sql(ops)\n",
    "    assert sql.find('|') < 0\n",
    "    assert sql.find('OR') > 0\n",
    "\n",
    "    expect = data_algebra.default_data_model.pd.DataFrame({\n",
    "        'group': ['b'],\n",
    "        'v1': [0],\n",
    "        'v2': [4],\n",
    "    })\n",
    "\n",
    "    data_algebra.test_util.check_transform_on_handles(\n",
    "        ops=ops,\n",
    "        data=d,\n",
    "        expect=expect,\n",
    "        db_handles=db_handles,\n",
    "        check_parse=False,\n",
    "    )\n",
    "\n",
    "\n",
    "test_big_query_notor()\n",
    "\n",
    "\n",
    "def test_TRIMSTR():\n",
    "    d = data_algebra.default_data_model.pd.DataFrame({\n",
    "        'x': ['0123456', 'abcdefghijk'],\n",
    "        'y': ['012345', 'abcdefghij'],\n",
    "    })\n",
    "    table_name = f'{data_catalog}.{data_schema}.pytest_temp_d'\n",
    "\n",
    "    ops = describe_table(d, table_name=table_name) .\\\n",
    "        extend({\n",
    "         'nx': bq_handle.fns.trimstr('x', start=0, stop=5)\n",
    "        })\n",
    "\n",
    "    expect = data_algebra.default_data_model.pd.DataFrame({\n",
    "        'x': ['0123456', 'abcdefghijk'],\n",
    "        'y': ['012345', 'abcdefghij'],\n",
    "        'nx': ['01234', 'abcde'],\n",
    "    })\n",
    "\n",
    "    data_algebra.test_util.check_transform_on_handles(\n",
    "        ops=ops,\n",
    "        data=d,\n",
    "        expect=expect,\n",
    "        db_handles=[bq_handle],\n",
    "        check_parse=False,\n",
    "    )\n",
    "\n",
    "\n",
    "test_TRIMSTR()\n",
    "\n",
    "\n",
    "def test_AS_INT64():\n",
    "    d = data_algebra.default_data_model.pd.DataFrame({\n",
    "        'x': ['0123456', '66'],\n",
    "        'y': ['012345', '77'],\n",
    "    })\n",
    "    table_name = f'{data_catalog}.{data_schema}.pytest_temp_d'\n",
    "\n",
    "    ops = describe_table(d, table_name=table_name) .\\\n",
    "        extend({\n",
    "         'nx': bq_handle.fns.as_int64('x')\n",
    "        })\n",
    "\n",
    "    expect = data_algebra.default_data_model.pd.DataFrame({\n",
    "        'x': ['0123456', '66'],\n",
    "        'y': ['012345', '77'],\n",
    "        'nx': [123456, 66]\n",
    "    })\n",
    "\n",
    "    data_algebra.test_util.check_transform_on_handles(\n",
    "        ops=ops,\n",
    "        data=d,\n",
    "        expect=expect,\n",
    "        db_handles=[bq_handle],\n",
    "        check_parse=False,\n",
    "    )\n",
    "\n",
    "\n",
    "test_AS_INT64()\n",
    "\n",
    "\n",
    "def test_DATE():\n",
    "    d = data_algebra.default_data_model.pd.DataFrame({\n",
    "        'x': data_algebra.default_data_model.pd.to_datetime([1490196805, 1490195835], unit='s'),\n",
    "        'y': ['012345', '77'],\n",
    "    })\n",
    "    table_name = f'{data_catalog}.{data_schema}.pytest_temp_d'\n",
    "\n",
    "    ops = describe_table(d, table_name=table_name) .\\\n",
    "        extend({\n",
    "         'nx': bq_handle.fns.datetime_to_date('x')\n",
    "        }) .\\\n",
    "        extend({\n",
    "         'nxs': bq_handle.fns.as_str('nx')\n",
    "        }) .\\\n",
    "        select_columns(['nxs'])\n",
    "\n",
    "    expect = data_algebra.default_data_model.pd.DataFrame({\n",
    "        'nxs': ['2017-03-22', '2017-03-22']\n",
    "    })\n",
    "\n",
    "    data_algebra.test_util.check_transform_on_handles(\n",
    "        ops=ops,\n",
    "        data=d,\n",
    "        expect=expect,\n",
    "        db_handles=[bq_handle],\n",
    "        check_parse=False,\n",
    "    )\n",
    "\n",
    "\n",
    "test_DATE()\n",
    "\n",
    "\n",
    "def test_COALESCE_0():\n",
    "    d = data_algebra.default_data_model.pd.DataFrame({\n",
    "        'x': [1, None, 3]\n",
    "    })\n",
    "    table_name = f'{data_catalog}.{data_schema}.pytest_temp_d'\n",
    "\n",
    "    ops = describe_table(d, table_name=table_name) .\\\n",
    "        extend({\n",
    "         'nx': bq_handle.fns.coalesce_0('x')\n",
    "        })\n",
    "\n",
    "    expect = data_algebra.default_data_model.pd.DataFrame({\n",
    "        'x': [1, None, 3],\n",
    "        'nx': [1, 0, 3]\n",
    "    })\n",
    "\n",
    "    data_algebra.test_util.check_transform_on_handles(\n",
    "        ops=ops,\n",
    "        data=d,\n",
    "        expect=expect,\n",
    "        db_handles=[bq_handle],\n",
    "        check_parse=False,\n",
    "    )\n",
    "\n",
    "\n",
    "test_COALESCE_0()\n",
    "\n",
    "def test_PARSE_DATE():\n",
    "    d = data_algebra.default_data_model.pd.DataFrame({\n",
    "        'x': ['2001-01-01', '2020-04-02']\n",
    "    })\n",
    "    table_name = f'{data_catalog}.{data_schema}.pytest_temp_d'\n",
    "\n",
    "    ops = describe_table(d, table_name=table_name) .\\\n",
    "        extend({\n",
    "         'nx': bq_handle.fns.parse_date('x')\n",
    "        })\n",
    "    res = ops.transform(d)\n",
    "    assert isinstance(res.nx[0], datetime.date)\n",
    "\n",
    "    expect = data_algebra.default_data_model.pd.DataFrame({\n",
    "        'x': ['2001-01-01', '2020-04-02']\n",
    "    })\n",
    "    expect['nx'] = data_algebra.default_data_model.pd.to_datetime(d.x, format=\"%Y-%m-%d\")\n",
    "    assert data_algebra.test_util.equivalent_frames(res, expect)\n",
    "\n",
    "    data_algebra.test_util.check_transform_on_handles(\n",
    "        ops=ops,\n",
    "        data=d,\n",
    "        expect=expect,\n",
    "        db_handles=[bq_handle],\n",
    "        check_parse=False,\n",
    "    )\n",
    "\n",
    "\n",
    "test_PARSE_DATE()\n",
    "\n",
    "\n",
    "def test_DATE_PARTS():\n",
    "    d = data_algebra.default_data_model.pd.DataFrame({\n",
    "        'x': ['2001-01-01', '2020-04-02'],\n",
    "        't': ['2001-01-01 01:33:22', '2020-04-02 13:11:10'],\n",
    "    })\n",
    "    table_name = f'{data_catalog}.{data_schema}.pytest_temp_d'\n",
    "\n",
    "    ops = describe_table(d, table_name=table_name) .\\\n",
    "        extend({\n",
    "            'nx': bq_handle.fns.parse_date('x', format=\"%Y-%m-%d\"),\n",
    "            'nt': bq_handle.fns.parse_datetime('t', format=\"%Y-%m-%d %H:%M:%S\"),\n",
    "            'nd': bq_handle.fns.parse_datetime('x', format=\"%Y-%m-%d\"),\n",
    "        }) .\\\n",
    "        extend({\n",
    "            'date2': bq_handle.fns.datetime_to_date('nt'),\n",
    "            'day_of_week': bq_handle.fns.dayofweek('nx'),\n",
    "            'day_of_year': bq_handle.fns.dayofyear('nx'),\n",
    "            'month': bq_handle.fns.month('nx'),\n",
    "            'day_of_month': bq_handle.fns.dayofmonth('nx'),\n",
    "            'quarter': bq_handle.fns.quarter('nx'),\n",
    "            'year': bq_handle.fns.year('nx'),\n",
    "            'diff': bq_handle.fns.timestamp_diff('nt', 'nd'),\n",
    "            'sdt': bq_handle.fns.format_datetime('nt', format=\"%Y-%m-%d %H:%M:%S\"),\n",
    "            'sd': bq_handle.fns.format_date('nx', format=\"%Y-%m-%d\"),\n",
    "            'dd': bq_handle.fns.date_diff('nx', 'nx'),\n",
    "        })\n",
    "    res = ops.transform(d)\n",
    "    assert isinstance(res.nx[0], datetime.date)\n",
    "    assert isinstance(res.sdt[0], str)\n",
    "    assert isinstance(res.sd[0], str)\n",
    "\n",
    "    expect = data_algebra.default_data_model.pd.DataFrame({\n",
    "        'x': ['2001-01-01', '2020-04-02'],\n",
    "        't': ['2001-01-01 01:33:22', '2020-04-02 13:11:10'],\n",
    "        'day_of_week': [2, 5],\n",
    "        'day_of_year': [1, 93],\n",
    "        'month': [1, 4],\n",
    "        'day_of_month': [1, 2],\n",
    "        'quarter': [1, 2],\n",
    "        'year': [2001, 2020],\n",
    "        'dd': [0, 0],\n",
    "    })\n",
    "    expect['nx'] = data_algebra.default_data_model.pd.to_datetime(expect.x, format=\"%Y-%m-%d\").dt.date.copy()\n",
    "    expect['nt'] = data_algebra.default_data_model.pd.to_datetime(expect.t, format=\"%Y-%m-%d %H:%M:%S\")\n",
    "    expect['nd'] = data_algebra.default_data_model.pd.to_datetime(expect.x, format=\"%Y-%m-%d\")\n",
    "    expect['date2'] = expect.nt.dt.date.copy()\n",
    "    expect['diff'] = [\n",
    "            data_algebra.default_data_model.pd.Timedelta(expect['nt'][i] - expect['nd'][i]).total_seconds()\n",
    "            for i in range(len(expect['nt']))]\n",
    "    expect['sdt'] = expect.t\n",
    "    expect['sd'] = expect.x\n",
    "\n",
    "    data_algebra.test_util.check_transform_on_handles(\n",
    "        ops=ops,\n",
    "        data=d,\n",
    "        expect=expect,\n",
    "        db_handles=[bq_handle],\n",
    "        check_parse=False,\n",
    "    )\n",
    "\n",
    "\n",
    "test_DATE_PARTS()\n",
    "\n",
    "\n",
    "def test_coalesce():\n",
    "    d = data_algebra.default_data_model.pd.DataFrame({\n",
    "        'a': [1, None, None, None, None, 6, 7, None],\n",
    "        'b': [10, 20, None, None, None, 60, None, None],\n",
    "        'c': [None, 200, 300, None, 500, 600, 700, None],\n",
    "        'd': [1000, None, 3000, 4000, None, 6000, None, None],\n",
    "    })\n",
    "    table_name = f'{data_catalog}.{data_schema}.pytest_temp_d'\n",
    "\n",
    "    ops = describe_table(d, table_name=table_name)  .\\\n",
    "        extend({'fixed': bq_handle.fns.coalesce(['a','b', 'c', 'd'])})\n",
    "\n",
    "    expect = data_algebra.default_data_model.pd.DataFrame({\n",
    "        'a': [1, None, None, None, None, 6, 7, None],\n",
    "        'b': [10, 20, None, None, None, 60, None, None],\n",
    "        'c': [None, 200, 300, None, 500, 600, 700, None],\n",
    "        'd': [1000, None, 3000, 4000, None, 6000, None, None],\n",
    "        'fixed': [1, 20, 300, 4000, 500, 6, 7, None],\n",
    "    })\n",
    "\n",
    "    data_algebra.test_util.check_transform_on_handles(\n",
    "        ops=ops,\n",
    "        data=d,\n",
    "        expect=expect,\n",
    "        db_handles=[bq_handle],\n",
    "        check_parse=False,\n",
    "    )\n",
    "\n",
    "test_coalesce()\n",
    "\n",
    "\n",
    "def test_base_Sunday():\n",
    "    d = data_algebra.default_data_model.pd.DataFrame({\n",
    "        'date_str': ['2021-04-25', '2021-04-27']\n",
    "    })\n",
    "    table_name = f'{data_catalog}.{data_schema}.pytest_temp_d'\n",
    "\n",
    "    ops = describe_table(d, table_name=table_name) .\\\n",
    "        extend({\n",
    "            'dt': bq_handle.fns.parse_date('date_str', format=\"%Y-%m-%d\")\n",
    "        }) .\\\n",
    "        extend({\n",
    "            's': bq_handle.fns.base_Sunday('dt')\n",
    "        }) .\\\n",
    "        drop_columns(['dt']) .\\\n",
    "        extend({\n",
    "            's': bq_handle.fns.format_date('s', format=\"%Y-%m-%d\")\n",
    "        })\n",
    "\n",
    "    expect = data_algebra.default_data_model.pd.DataFrame({\n",
    "        'date_str': ['2021-04-25', '2021-04-27'],\n",
    "        's': ['2021-04-25', '2021-04-25']\n",
    "    })\n",
    "\n",
    "    data_algebra.test_util.check_transform_on_handles(\n",
    "        ops=ops,\n",
    "        data=d,\n",
    "        expect=expect,\n",
    "        db_handles=[bq_handle],\n",
    "        check_parse=False,\n",
    "    )\n",
    "\n",
    "\n",
    "test_base_Sunday()\n",
    "\n",
    "\n",
    "def test_bq_concat_rows():\n",
    "    d = data_algebra.default_data_model.pd.DataFrame({\n",
    "        'd': [1, 2]\n",
    "    })\n",
    "    table_name = f'{data_catalog}.{data_schema}.pytest_temp_d'\n",
    "\n",
    "    ops = describe_table(d, table_name=table_name) .\\\n",
    "        extend({'d': 'd + 1'}) .\\\n",
    "        concat_rows(b=describe_table(d, table_name=table_name))\n",
    "\n",
    "    expect = data_algebra.default_data_model.pd.DataFrame({\n",
    "        'd': [2, 3, 1, 2],\n",
    "        'source_name': ['a', 'a', 'b', 'b']\n",
    "    })\n",
    "\n",
    "    data_algebra.test_util.check_transform_on_handles(\n",
    "        ops=ops,\n",
    "        data=d,\n",
    "        expect=expect,\n",
    "        db_handles=[bq_handle],\n",
    "        check_parse=False,\n",
    "    )\n",
    "\n",
    "\n",
    "test_bq_concat_rows()\n",
    "\n",
    "\n",
    "def test_bq_join_rows():\n",
    "    d1 = data_algebra.default_data_model.pd.DataFrame({\n",
    "        'k': ['a', 'b'],\n",
    "        'd': [1, 2]\n",
    "    })\n",
    "    table_name_d1 = f'{data_catalog}.{data_schema}.pytest_temp_d1'\n",
    "    d2 = data_algebra.default_data_model.pd.DataFrame({\n",
    "        'k': ['a', 'b'],\n",
    "        'e': [4, 5]\n",
    "    })\n",
    "    table_name_d2 = f'{data_catalog}.{data_schema}.pytest_temp_d2'\n",
    "\n",
    "    ops = describe_table(d1, table_name=table_name_d1) .\\\n",
    "        extend({'d': 'd + 1'}) .\\\n",
    "        natural_join(b=describe_table(d2, table_name=table_name_d2),\n",
    "                     by=['k'],\n",
    "                     jointype='inner')\n",
    "\n",
    "    expect = data_algebra.default_data_model.pd.DataFrame({\n",
    "        'k': ['a', 'b'],\n",
    "        'd': [2, 3],\n",
    "        'e': [4, 5],\n",
    "    })\n",
    "\n",
    "    data_algebra.test_util.check_transform_on_handles(\n",
    "        ops=ops,\n",
    "        data={table_name_d1: d1, table_name_d2: d2},\n",
    "        expect=expect,\n",
    "        db_handles=db_handles,\n",
    "        check_parse=False,\n",
    "    )\n",
    "\n",
    "\n",
    "test_bq_join_rows()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "\n",
    "def test_ideom_extend_one_count():\n",
    "    d = data_algebra.default_data_model.pd.DataFrame({\n",
    "        'group': ['a', 'a', 'b', 'b'],\n",
    "        'val': [1, 2, 3, 4],\n",
    "    })\n",
    "    table_name = f'{data_catalog}.{data_schema}.pytest_temp_d'\n",
    "\n",
    "    ops = describe_table(d, table_name=table_name) .\\\n",
    "        extend({\n",
    "            'one': 1\n",
    "        }) .\\\n",
    "        project({\n",
    "            'count': 'one.sum()'\n",
    "        })\n",
    "\n",
    "    expect = data_algebra.default_data_model.pd.DataFrame({\n",
    "        'count': [4]\n",
    "    })\n",
    "\n",
    "    data_algebra.test_util.check_transform_on_handles(\n",
    "        ops=ops,\n",
    "        data=d,\n",
    "        expect=expect,\n",
    "        db_handles=db_handles,\n",
    "        check_parse=False,\n",
    "    )\n",
    "\n",
    "\n",
    "test_ideom_extend_one_count()\n",
    "\n",
    "\n",
    "def test_ideom_extend_special_count():\n",
    "    d = data_algebra.default_data_model.pd.DataFrame({\n",
    "        'group': ['a', 'a', 'b', 'b'],\n",
    "        'val': [1, 2, 3, 4],\n",
    "    })\n",
    "    table_name = f'{data_catalog}.{data_schema}.pytest_temp_d'\n",
    "\n",
    "    ops = describe_table(d, table_name=table_name) .\\\n",
    "        project({\n",
    "            'count': '_count()'\n",
    "        })\n",
    "\n",
    "    expect = data_algebra.default_data_model.pd.DataFrame({\n",
    "        'count': [4]\n",
    "    })\n",
    "\n",
    "    data_algebra.test_util.check_transform_on_handles(\n",
    "        ops=ops,\n",
    "        data=d,\n",
    "        expect=expect,\n",
    "        db_handles=db_handles,\n",
    "        check_parse=False,\n",
    "    )\n",
    "\n",
    "\n",
    "test_ideom_extend_special_count()\n",
    "\n",
    "\n",
    "# previously forbidden\n",
    "def test_ideom_forbidden_extend_test_trinary():\n",
    "    d = data_algebra.default_data_model.pd.DataFrame({\n",
    "        'group': ['a', 'a', 'b', 'b'],\n",
    "        'val': [1, 2, 3, 4],\n",
    "    })\n",
    "    table_name = f'{data_catalog}.{data_schema}.pytest_temp_d'\n",
    "\n",
    "    ops = describe_table(d, table_name=table_name) .\\\n",
    "        extend({ # {'select': '(val > 2.5).if_else(\"high\", \"low\")' } # doesn't work in Pandas\n",
    "            'select': '(val > 2.5).if_else(\"high\", \"low\")'\n",
    "        })\n",
    "\n",
    "    expect = data_algebra.default_data_model.pd.DataFrame({\n",
    "        'group': ['a', 'a', 'b', 'b'],\n",
    "        'val': [1, 2, 3, 4],\n",
    "        'select': ['low', 'low', 'high', 'high']\n",
    "    })\n",
    "\n",
    "    data_algebra.test_util.check_transform_on_handles(\n",
    "        ops=ops,\n",
    "        data=d,\n",
    "        expect=expect,\n",
    "        db_handles=db_handles,\n",
    "        check_parse=False,\n",
    "    )\n",
    "\n",
    "\n",
    "test_ideom_forbidden_extend_test_trinary()\n",
    "\n",
    "\n",
    "def test_ideom_extend_test_trinary():\n",
    "    d = data_algebra.default_data_model.pd.DataFrame({\n",
    "        'group': ['a', 'a', 'b', 'b'],\n",
    "        'val': [1, 2, 3, 4],\n",
    "    })\n",
    "    table_name = f'{data_catalog}.{data_schema}.pytest_temp_d'\n",
    "\n",
    "    ops = describe_table(d, table_name=table_name) .\\\n",
    "        extend({ # {'select': '(val > 2.5).if_else(\"high\", \"low\")' } # doesn't work in Pandas\n",
    "            'select': '(val > 2.5)'\n",
    "        }) .\\\n",
    "        extend({\n",
    "            'select': 'select.if_else(\"high\", \"low\")'\n",
    "        })\n",
    "\n",
    "    expect = data_algebra.default_data_model.pd.DataFrame({\n",
    "        'group': ['a', 'a', 'b', 'b'],\n",
    "        'val': [1, 2, 3, 4],\n",
    "        'select': ['low', 'low', 'high', 'high']\n",
    "    })\n",
    "\n",
    "    data_algebra.test_util.check_transform_on_handles(\n",
    "        ops=ops,\n",
    "        data=d,\n",
    "        expect=expect,\n",
    "        db_handles=db_handles,\n",
    "        check_parse=False,\n",
    "    )\n",
    "\n",
    "\n",
    "test_ideom_extend_test_trinary()\n",
    "\n",
    "\n",
    "def test_ideom_simulate_cross_join():\n",
    "    d = data_algebra.default_data_model.pd.DataFrame({\n",
    "        'x': [1, 2, 3, 4],\n",
    "    })\n",
    "    table_name_d = f'{data_catalog}.{data_schema}.pytest_temp_d'\n",
    "\n",
    "    e = data_algebra.default_data_model.pd.DataFrame({\n",
    "        'y': ['a', 'b', 'c'],\n",
    "    })\n",
    "    table_name_e = f'{data_catalog}.{data_schema}.pytest_temp_e'\n",
    "\n",
    "    ops = describe_table(d, table_name=table_name_d) .\\\n",
    "        extend({ # {'select': '(val > 2.5).if_else(\"high\", \"low\")' } # doesn't work in Pandas\n",
    "            'one': 1\n",
    "        }) .\\\n",
    "        natural_join(\n",
    "            b=describe_table(e, table_name=table_name_e) . \\\n",
    "                extend({  # {'select': '(val > 2.5).if_else(\"high\", \"low\")' } # doesn't work in Pandas\n",
    "                    'one': 1\n",
    "                }),\n",
    "            by=['one'],\n",
    "            jointype='left'\n",
    "        ) .\\\n",
    "        drop_columns(['one'])\n",
    "\n",
    "    expect = data_algebra.default_data_model.pd.DataFrame({\n",
    "        'x': [1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4],\n",
    "        'y': ['a', 'b', 'c', 'a', 'b', 'c', 'a', 'b', 'c', 'a', 'b', 'c'],\n",
    "    })\n",
    "\n",
    "    data_algebra.test_util.check_transform_on_handles(\n",
    "        ops=ops,\n",
    "        data={table_name_d: d, table_name_e: e},\n",
    "        expect=expect,\n",
    "        db_handles=db_handles,\n",
    "        check_parse=False,\n",
    "    )\n",
    "\n",
    "\n",
    "test_ideom_simulate_cross_join()\n",
    "\n",
    "\n",
    "def test_ideom_simulate_cross_join_select():\n",
    "    d = data_algebra.default_data_model.pd.DataFrame({\n",
    "        'x': [1, 2, 3, 4],\n",
    "    })\n",
    "    table_name_d = f'{data_catalog}.{data_schema}.pytest_temp_d'\n",
    "\n",
    "    e = data_algebra.default_data_model.pd.DataFrame({\n",
    "        'y': ['a', 'b', 'c'],\n",
    "    })\n",
    "    table_name_e = f'{data_catalog}.{data_schema}.pytest_temp_e'\n",
    "\n",
    "    ops = describe_table(d, table_name=table_name_d) .\\\n",
    "        extend({ # {'select': '(val > 2.5).if_else(\"high\", \"low\")' } # doesn't work in Pandas\n",
    "            'one': 1\n",
    "        }) .\\\n",
    "        natural_join(\n",
    "            b=describe_table(e, table_name=table_name_e) . \\\n",
    "                extend({  # {'select': '(val > 2.5).if_else(\"high\", \"low\")' } # doesn't work in Pandas\n",
    "                    'one': 1\n",
    "                }),\n",
    "            by=['one'],\n",
    "            jointype='left'\n",
    "        ) .\\\n",
    "        select_columns(['x', 'y'])\n",
    "\n",
    "    expect = data_algebra.default_data_model.pd.DataFrame({\n",
    "        'x': [1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4],\n",
    "        'y': ['a', 'b', 'c', 'a', 'b', 'c', 'a', 'b', 'c', 'a', 'b', 'c'],\n",
    "    })\n",
    "\n",
    "    data_algebra.test_util.check_transform_on_handles(\n",
    "        ops=ops,\n",
    "        data={table_name_d: d, table_name_e: e},\n",
    "        expect=expect,\n",
    "        db_handles=db_handles,\n",
    "        check_parse=False,\n",
    "    )\n",
    "\n",
    "\n",
    "test_ideom_simulate_cross_join_select()\n",
    "\n",
    "\n",
    "def test_ideom_cross_join():\n",
    "    d = data_algebra.default_data_model.pd.DataFrame({\n",
    "        'x': [1, 2, 3, 4],\n",
    "    })\n",
    "    table_name_d = f'{data_catalog}.{data_schema}.pytest_temp_d'\n",
    "\n",
    "    e = data_algebra.default_data_model.pd.DataFrame({\n",
    "        'y': ['a', 'b', 'c'],\n",
    "    })\n",
    "    table_name_e = f'{data_catalog}.{data_schema}.pytest_temp_e'\n",
    "\n",
    "    ops = describe_table(d, table_name=table_name_d) .\\\n",
    "        natural_join(\n",
    "            b=describe_table(e, table_name=table_name_e),\n",
    "            by=[],\n",
    "            jointype='cross'\n",
    "        )\n",
    "\n",
    "    expect = data_algebra.default_data_model.pd.DataFrame({\n",
    "        'x': [1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4],\n",
    "        'y': ['a', 'b', 'c', 'a', 'b', 'c', 'a', 'b', 'c', 'a', 'b', 'c'],\n",
    "    })\n",
    "\n",
    "    data_algebra.test_util.check_transform_on_handles(\n",
    "        ops=ops,\n",
    "        data={table_name_d: d, table_name_e: e},\n",
    "        expect=expect,\n",
    "        db_handles=db_handles,\n",
    "        check_parse=False,\n",
    "    )\n",
    "\n",
    "\n",
    "test_ideom_cross_join()\n",
    "\n",
    "\n",
    "# Note: switching from _row_number to _count\n",
    "def test_ideom_row_number():\n",
    "    d = data_algebra.default_data_model.pd.DataFrame({\n",
    "        'i': [1, 3, 2, 4, 5],\n",
    "        'g': [1, 2, 2, 1, 1],\n",
    "    })\n",
    "    table_name_d = f'{data_catalog}.{data_schema}.pytest_temp_d'\n",
    "\n",
    "    ops = describe_table(d, table_name=table_name_d) .\\\n",
    "        extend({\n",
    "            'one': 1\n",
    "            }) .\\\n",
    "        extend({\n",
    "            'n': 'one.cumsum()'\n",
    "            },\n",
    "            partition_by=['g'],\n",
    "            order_by=['i'],\n",
    "            ) .\\\n",
    "        drop_columns(['one']) .\\\n",
    "        order_rows(['i'])\n",
    "\n",
    "    expect = data_algebra.default_data_model.pd.DataFrame({\n",
    "        'i': [1, 2, 3, 4, 5],\n",
    "        'g': [1, 2, 2, 1, 1],\n",
    "        'n': [1, 1, 2, 2, 3],\n",
    "    })\n",
    "\n",
    "    data_algebra.test_util.check_transform_on_handles(\n",
    "        ops=ops,\n",
    "        data=d,\n",
    "        expect=expect,\n",
    "        db_handles=db_handles,\n",
    "        check_parse=False,\n",
    "    )\n",
    "\n",
    "\n",
    "test_ideom_row_number()\n",
    "\n",
    "\n",
    "def test_ideom_sum_cumsum():\n",
    "    d = data_algebra.default_data_model.pd.DataFrame({\n",
    "        'i': [1, 2, 3, 4, 5],\n",
    "        'o': [1, 1, 1, 1, 1],\n",
    "        'g': [1, 2, 2, 1, 1],\n",
    "    })\n",
    "    table_name_d = f'{data_catalog}.{data_schema}.pytest_temp_d'\n",
    "\n",
    "    with pytest.raises(ValueError):\n",
    "        ops = describe_table(d, table_name=table_name_d). \\\n",
    "                extend({\n",
    "                's2': 'o.sum()',\n",
    "                },\n",
    "                partition_by=['g'],\n",
    "                order_by=['i'],\n",
    "            )\n",
    "\n",
    "    with pytest.raises(ValueError):\n",
    "        ops = describe_table(d, table_name=table_name_d). \\\n",
    "                extend({\n",
    "                's2': 'o.cumsum()',\n",
    "                },\n",
    "                partition_by=['g'],\n",
    "            )\n",
    "\n",
    "    ops = describe_table(d, table_name=table_name_d). \\\n",
    "        extend({\n",
    "            's': '(1).cumsum()',\n",
    "            },\n",
    "            partition_by=['g'],\n",
    "            order_by=['i'],\n",
    "            ). \\\n",
    "        extend({\n",
    "            'n': 's.max()',  # max over cumsum to get sum!\n",
    "            'n2': '(1).sum()',  # no order present, so meaning is non-cumulative.\n",
    "            },\n",
    "            partition_by=['g']\n",
    "        ). \\\n",
    "        order_rows(['i'])\n",
    "\n",
    "    expect = data_algebra.default_data_model.pd.DataFrame({\n",
    "        'i':  [1, 2, 3, 4, 5],\n",
    "        'o':  [1, 1, 1, 1, 1],\n",
    "        'g':  [1, 2, 2, 1, 1],\n",
    "        'n':  [3, 2, 2, 3, 3],\n",
    "        'n2': [3, 2, 2, 3, 3],\n",
    "        's':  [1, 1, 2, 2, 3],\n",
    "    })\n",
    "\n",
    "    data_algebra.test_util.check_transform_on_handles(\n",
    "        ops=ops,\n",
    "        data=d,\n",
    "        expect=expect,\n",
    "        db_handles=db_handles,\n",
    "        check_parse=False,\n",
    "    )\n",
    "\n",
    "\n",
    "test_ideom_sum_cumsum()\n",
    "\n",
    "\n",
    "def test_ideom_project_sum():\n",
    "    d = data_algebra.default_data_model.pd.DataFrame({\n",
    "        'i': [1, 2, 3, 4, 5],\n",
    "        'g': [1, 2, 2, 1, 1],\n",
    "    })\n",
    "    table_name_d = f'{data_catalog}.{data_schema}.pytest_temp_d'\n",
    "\n",
    "    ops = describe_table(d, table_name=table_name_d). \\\n",
    "        project({\n",
    "            's': '(1).sum()',\n",
    "            },\n",
    "            group_by=['g'],\n",
    "            ). \\\n",
    "        order_rows(['g'])\n",
    "\n",
    "    expect = data_algebra.default_data_model.pd.DataFrame({\n",
    "        'g':  [1, 2],\n",
    "        's':  [3, 2],\n",
    "    })\n",
    "\n",
    "    data_algebra.test_util.check_transform_on_handles(\n",
    "        ops=ops,\n",
    "        data=d,\n",
    "        expect=expect,\n",
    "        db_handles=db_handles,\n",
    "        check_parse=False,\n",
    "    )\n",
    "\n",
    "\n",
    "test_ideom_project_sum()\n",
    "\n",
    "\n",
    "def test_ideom_concat_op():\n",
    "    d = data_algebra.default_data_model.pd.DataFrame({\n",
    "        'x': ['a', 'b', 'c'],\n",
    "        'y': ['1', '2', '3'],\n",
    "    })\n",
    "    table_name_d = f'{data_catalog}.{data_schema}.pytest_temp_d'\n",
    "\n",
    "    ops = describe_table(d, table_name=table_name_d). \\\n",
    "        extend({\n",
    "            'z': 'x %+% y %+% + x'\n",
    "            })\n",
    "\n",
    "    expect = data_algebra.default_data_model.pd.DataFrame({\n",
    "        'x': ['a', 'b', 'c'],\n",
    "        'y': ['1', '2', '3'],\n",
    "        'z': ['a1a', 'b2b', 'c3c']\n",
    "    })\n",
    "\n",
    "    data_algebra.test_util.check_transform_on_handles(\n",
    "        ops=ops,\n",
    "        data=d,\n",
    "        expect=expect,\n",
    "        db_handles=db_handles,\n",
    "        check_parse=False,\n",
    "    )\n",
    "\n",
    "\n",
    "test_ideom_concat_op()\n",
    "\n",
    "\n",
    "def test_ideom_coalesce_op():\n",
    "    d = data_algebra.default_data_model.pd.DataFrame({\n",
    "        'x': ['a', 'b', None, None],\n",
    "        'y': ['1', None, '3', None],\n",
    "    })\n",
    "    table_name_d = f'{data_catalog}.{data_schema}.pytest_temp_d'\n",
    "\n",
    "    ops = describe_table(d, table_name=table_name_d). \\\n",
    "        extend({\n",
    "            'z': 'x %?% y'\n",
    "            })\n",
    "\n",
    "    expect = data_algebra.default_data_model.pd.DataFrame({\n",
    "        'x': ['a', 'b', None, None],\n",
    "        'y': ['1', None, '3', None],\n",
    "        'z': ['a', 'b', '3', None],\n",
    "    })\n",
    "\n",
    "    data_algebra.test_util.check_transform_on_handles(\n",
    "        ops=ops,\n",
    "        data=d,\n",
    "        expect=expect,\n",
    "        db_handles=db_handles,\n",
    "        check_parse=False,\n",
    "    )\n",
    "\n",
    "\n",
    "test_ideom_coalesce_op()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# clean up\n",
    "bq_handle.close()\n",
    "db_handle_sqlite.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "2"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 + 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}