{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## A catalog of [data algebra expression](https://github.com/WinVector/data_algebra) methods.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "from data_algebra.data_ops import *\n",
    "import data_algebra.SQLite\n",
    "import data_algebra.BigQuery\n",
    "import data_algebra.PostgreSQL\n",
    "import data_algebra.SparkSQL\n",
    "import data_algebra.MySQL\n",
    "from data_algebra.parse_by_lark import parse_by_lark\n",
    "import data_algebra.test_util\n",
    "import data_algebra.util\n",
    "\n",
    "\n",
    "def mk_example():\n",
    "    datetime_format = \"%Y-%m-%d %H:%M:%S\"\n",
    "    date_format = \"%Y-%m-%d\"\n",
    "    d = pd.DataFrame({\n",
    "        'row_id': [0, 1, 2, 3],\n",
    "        'a': [False, False, True, True],\n",
    "        'b': [False, True, False, True],\n",
    "        'q': [1, 1, 2, 2],\n",
    "        'x': [.1, .2, .3, .4],\n",
    "        'y': [2.4, 1.33, 1.2, 1.1],\n",
    "        'z': [1.6, None, -2.1, numpy.nan],\n",
    "        'g': ['a', 'a', 'b', 'ccc'],\n",
    "        's2': ['z', 'q', '11', 'b'],\n",
    "        \"str_datetime_col\": [\"2000-01-01 12:13:21\", \"2020-04-05 14:03:00\", \"2000-01-01 12:13:21\", \"2020-04-05 14:03:00\"],\n",
    "        \"str_date_col\": [\"2000-03-01\", \"2020-04-05\", \"2000-03-01\", \"2020-04-05\"],\n",
    "        \"datetime_col_0\": pd.to_datetime(\n",
    "            pd.Series([\"2010-01-01 12:13:21\", \"2030-04-05 14:03:00\", \"2010-01-01 12:13:21\", \"2030-04-05 14:03:00\"]),\n",
    "            format=datetime_format,\n",
    "        ),\n",
    "        \"datetime_col_1\": pd.to_datetime(\n",
    "            pd.Series([\"2010-01-01 12:11:21\", \"2030-04-06 14:03:00\", \"2010-01-01 12:11:21\", \"2030-04-06 14:03:00\"]),\n",
    "            format=date_format,\n",
    "        ),\n",
    "        \"date_col_0\": pd.to_datetime(\n",
    "            pd.Series([\"2000-01-02\", \"2035-04-05\", \"2000-01-02\", \"2035-04-05\"]),\n",
    "            format=date_format\n",
    "        ).dt.date,\n",
    "        \"date_col_1\": pd.to_datetime(\n",
    "            pd.Series([\"2000-01-02\", \"2035-05-05\", \"2000-01-02\", \"2035-05-05\"]),\n",
    "            format=date_format\n",
    "        ).dt.date,\n",
    "    })\n",
    "    return d\n",
    "\n",
    "\n",
    "def f(expression):\n",
    "    return (\n",
    "        descr(d=d)\n",
    "            .extend({'new_column': expression})\n",
    "            .select_columns(['row_id', 'new_column'])\n",
    "            .order_rows(['row_id'])\n",
    "    )\n",
    "\n",
    "\n",
    "def fg(expression):\n",
    "    return (\n",
    "        descr(d=d)\n",
    "            .extend(\n",
    "                {'new_column': expression},\n",
    "                partition_by=['g'])\n",
    "            .select_columns(['g', 'row_id', 'new_column'])\n",
    "            .order_rows(['g', 'row_id'])\n",
    "    )\n",
    "\n",
    "\n",
    "def fp(expression):\n",
    "    return (\n",
    "        descr(d=d)\n",
    "            .project(\n",
    "                {'new_column': expression},\n",
    "                group_by=['g'])\n",
    "            .order_rows(['g'])\n",
    "    )\n",
    "\n",
    "\n",
    "def fw(expression):\n",
    "    return (\n",
    "        descr(d=d)\n",
    "            .extend(\n",
    "                {'new_column': expression},\n",
    "                partition_by=['g'],\n",
    "                order_by=['row_id'])\n",
    "            .select_columns(['g', 'row_id', 'new_column'])\n",
    "            .order_rows(['g', 'row_id'])\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "   row_id      a      b  q    x     y    z    g  s2     str_datetime_col  \\\n0       0  False  False  1  0.1  2.40  1.6    a   z  2000-01-01 12:13:21   \n1       1  False   True  1  0.2  1.33  NaN    a   q  2020-04-05 14:03:00   \n2       2   True  False  2  0.3  1.20 -2.1    b  11  2000-01-01 12:13:21   \n3       3   True   True  2  0.4  1.10  NaN  ccc   b  2020-04-05 14:03:00   \n\n  str_date_col      datetime_col_0      datetime_col_1  date_col_0  date_col_1  \n0   2000-03-01 2010-01-01 12:13:21 2010-01-01 12:11:21  2000-01-02  2000-01-02  \n1   2020-04-05 2030-04-05 14:03:00 2030-04-06 14:03:00  2035-04-05  2035-05-05  \n2   2000-03-01 2010-01-01 12:13:21 2010-01-01 12:11:21  2000-01-02  2000-01-02  \n3   2020-04-05 2030-04-05 14:03:00 2030-04-06 14:03:00  2035-04-05  2035-05-05  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>row_id</th>\n      <th>a</th>\n      <th>b</th>\n      <th>q</th>\n      <th>x</th>\n      <th>y</th>\n      <th>z</th>\n      <th>g</th>\n      <th>s2</th>\n      <th>str_datetime_col</th>\n      <th>str_date_col</th>\n      <th>datetime_col_0</th>\n      <th>datetime_col_1</th>\n      <th>date_col_0</th>\n      <th>date_col_1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>1</td>\n      <td>0.1</td>\n      <td>2.40</td>\n      <td>1.6</td>\n      <td>a</td>\n      <td>z</td>\n      <td>2000-01-01 12:13:21</td>\n      <td>2000-03-01</td>\n      <td>2010-01-01 12:13:21</td>\n      <td>2010-01-01 12:11:21</td>\n      <td>2000-01-02</td>\n      <td>2000-01-02</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>False</td>\n      <td>True</td>\n      <td>1</td>\n      <td>0.2</td>\n      <td>1.33</td>\n      <td>NaN</td>\n      <td>a</td>\n      <td>q</td>\n      <td>2020-04-05 14:03:00</td>\n      <td>2020-04-05</td>\n      <td>2030-04-05 14:03:00</td>\n      <td>2030-04-06 14:03:00</td>\n      <td>2035-04-05</td>\n      <td>2035-05-05</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>True</td>\n      <td>False</td>\n      <td>2</td>\n      <td>0.3</td>\n      <td>1.20</td>\n      <td>-2.1</td>\n      <td>b</td>\n      <td>11</td>\n      <td>2000-01-01 12:13:21</td>\n      <td>2000-03-01</td>\n      <td>2010-01-01 12:13:21</td>\n      <td>2010-01-01 12:11:21</td>\n      <td>2000-01-02</td>\n      <td>2000-01-02</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>True</td>\n      <td>True</td>\n      <td>2</td>\n      <td>0.4</td>\n      <td>1.10</td>\n      <td>NaN</td>\n      <td>ccc</td>\n      <td>b</td>\n      <td>2020-04-05 14:03:00</td>\n      <td>2020-04-05</td>\n      <td>2030-04-05 14:03:00</td>\n      <td>2030-04-06 14:03:00</td>\n      <td>2035-04-05</td>\n      <td>2035-05-05</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = mk_example()\n",
    "\n",
    "d\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "data_def = {k: v for (k, v) in descr(d=d).column_map().items()}\n",
    "\n",
    "def parse(exp):\n",
    "    return parse_by_lark(exp, data_def=data_def)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "expressions = [\n",
    "    'x + y',\n",
    "    'x - y',\n",
    "    'row_id // q',\n",
    "    'row_id % q',\n",
    "    'x / y',\n",
    "    'x * y',\n",
    "    'x ** y',\n",
    "    'x == y',\n",
    "    'x > y',\n",
    "    'x >= y',\n",
    "    'x < y',\n",
    "    'x <= y',\n",
    "    'x != y',\n",
    "    '-x',\n",
    "    'not a',\n",
    "    'a & b',\n",
    "    'a and b',\n",
    "    'a | b',\n",
    "    'a or b',\n",
    "    'z.sign()',\n",
    "    'x.sin()',\n",
    "    'x.cos()',\n",
    "    'x.arcsin()',\n",
    "    'x.arccos()',\n",
    "    'x.arctan()',\n",
    "    'x.arctan2(y)',\n",
    "    'x.sinh()',\n",
    "    'x.cosh()',\n",
    "    'x.tanh()',\n",
    "    'x.arcsinh()',\n",
    "    'x.arccosh()',\n",
    "    'x.arctanh()',\n",
    "    'y.floor()',\n",
    "    'z.floor()',\n",
    "    'y.ceil()',\n",
    "    'z.ceil()',\n",
    "    'x.sum()',\n",
    "    'x.exp()',\n",
    "    'y.expm1()',\n",
    "    'x.log()',\n",
    "    'x.log10()',\n",
    "    'x.log1p()',\n",
    "    'y.mod(0.5)',\n",
    "    'y.remainder(0.5)',\n",
    "    'x.sqrt()',\n",
    "    'z.abs()',\n",
    "    'row_id.maximum(x)',\n",
    "    'row_id.minimum(x)',\n",
    "    'row_id.fmax(x)',\n",
    "    'row_id.fmin(x)',\n",
    "    'y.round()',\n",
    "    'y.around(2)',\n",
    "    'z.is_null()',\n",
    "    'z.is_bad()',\n",
    "    'a.if_else(x, y)',\n",
    "    'row_id.is_in({1, 3})',\n",
    "    'g.concat(s2)',\n",
    "    'g %+% \"_\" %+% s2',\n",
    "    'z.coalesce(2)',\n",
    "    'z %?% 2',\n",
    "    'z.coalesce_0()',\n",
    "    'g.mapv({\"a\": 1, \"b\": 2, \"z\": 26}, 0)',\n",
    "    'y.as_int64()',\n",
    "    'y.as_str()',\n",
    "    'g.trimstr(0, 2)',\n",
    "    'datetime_col_0.datetime_to_date()',\n",
    "    'str_date_col.parse_date()',\n",
    "    'str_datetime_col.parse_datetime()',\n",
    "    'datetime_col_0.format_datetime()',\n",
    "    'date_col_0.format_date()',\n",
    "    'date_col_0.dayofweek()',\n",
    "    'date_col_0.dayofyear()',\n",
    "    'date_col_0.dayofmonth()',\n",
    "    'date_col_0.weekofyear()',\n",
    "    'date_col_0.month()',\n",
    "    'date_col_0.quarter()',\n",
    "    'date_col_0.year()',\n",
    "    'datetime_col_0.timestamp_diff(datetime_col_1)',\n",
    "    'date_col_0.date_diff(date_col_1)',\n",
    "    'date_col_1.base_Sunday()',\n",
    "]\n",
    "\n",
    "grouped_expressions = [\n",
    "    'x.sum()',\n",
    "    '(1).sum()',\n",
    "    '_ngroup()',\n",
    "    'a.all()',\n",
    "    'a.any()',\n",
    "    'x.max()',\n",
    "    'x.mean()',\n",
    "    'x.median()',\n",
    "    'x.min()',\n",
    "    'x.nunique()',\n",
    "    'x.size()',\n",
    "    'z.count()',\n",
    "    '_size()',\n",
    "    '_count()',\n",
    "]\n",
    "\n",
    "project_expressions = [\n",
    "    'x.sum()',\n",
    "    '(1).sum()',\n",
    "    'a.all()',\n",
    "    'a.any()',\n",
    "    'x.max()',\n",
    "    'x.mean()',\n",
    "    'x.median()',\n",
    "    'x.min()',\n",
    "    'x.nunique()',\n",
    "    'x.size()',\n",
    "    'x.std()',\n",
    "    'x.var()',\n",
    "    'z.count()',\n",
    "    '_size()',\n",
    "]\n",
    "\n",
    "windowed_expressions = [\n",
    "    'z.bfill()',\n",
    "    'z.ffill()',\n",
    "    'x.last()',\n",
    "    'x.rank()',\n",
    "    'x.cumprod()',\n",
    "    'x.cumsum()',\n",
    "    'z.cumcount()',\n",
    "    'x.cummax()',\n",
    "    'x.cummin()',\n",
    "    'x.shift()',\n",
    "    '_row_number()',\n",
    "]\n",
    "\n",
    "u_expressions = [  # not simply checkable as output varies\n",
    "    '_uniform()',\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "e_expectations = [(parse(exp).op, 'e', exp, f(exp), f(exp).transform(d)) for exp in expressions]\n",
    "g_expectations = [(parse(exp).op, 'g', exp, fg(exp), fg(exp).transform(d)) for exp in grouped_expressions]\n",
    "p_expectations = [(parse(exp).op, 'p', exp, fp(exp), fp(exp).transform(d)) for exp in project_expressions]\n",
    "w_expectations = [(parse(exp).op, 'w', exp, fw(exp), fw(exp).transform(d)) for exp in windowed_expressions]\n",
    "u_results = [(parse(exp).op, 'u', exp, f(exp), f(exp).transform(d)) for exp in u_expressions]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "with gzip.open('expr_expectations.pkl.gz', 'wb') as out_f:\n",
    "    pickle.dump(\n",
    "        {\n",
    "            'd': d,\n",
    "            'e_expectations': e_expectations,\n",
    "            'g_expectations': g_expectations,\n",
    "            'p_expectations': p_expectations,\n",
    "            'w_expectations': w_expectations,\n",
    "            'u_results': u_results,\n",
    "        },\n",
    "        out_f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/18 08:09:34 WARN Utils: Your hostname, JAMiMac.local resolves to a loopback address: 127.0.0.1; using 192.168.0.155 instead (on interface en1)\n",
      "22/01/18 08:09:34 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/01/18 08:09:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "ops_list = e_expectations + g_expectations + p_expectations + w_expectations + u_results\n",
    "\n",
    "op_catalog = pd.DataFrame({\n",
    "    'op': [op for op, op_class, exp, ops, expect in ops_list],\n",
    "    'expression': [exp for op, op_class, exp, ops, expect in ops_list],\n",
    "    'op_class': [op_class for op, op_class, exp, ops, expect in ops_list],\n",
    "})\n",
    "op_catalog['Pandas'] = 'y'\n",
    "\n",
    "\n",
    "def test_on_db(db_handle, *, msg_file):\n",
    "    # test on db\n",
    "    res_vector = ['?'] * len(ops_list)\n",
    "    db_handle.insert_table(d, table_name='d', allow_overwrite=True)\n",
    "    for i in range(len(ops_list)):\n",
    "        op = ops_list[i][0]\n",
    "        op_class = ops_list[i][1]\n",
    "        exp = ops_list[i][2]\n",
    "        ops = ops_list[i][3]\n",
    "        expect = ops_list[i][4]\n",
    "        try:\n",
    "            res = db_handle.read_query(ops)\n",
    "            if op_class != 'u':\n",
    "                if data_algebra.test_util.equivalent_frames(res, expect):\n",
    "                    res_vector[i] = 'y'\n",
    "                else:\n",
    "                    res_vector[i] = 'w'\n",
    "                    print(\"\", file=msg_file)\n",
    "                    print(\"difference (w)\",\n",
    "                          file=msg_file)\n",
    "                    print(f'op: {op}, op_class: {op_class}, example expression: {exp}, db: {db_handle.db_model}',\n",
    "                          file=msg_file)\n",
    "                    print(\"Pandas result (expectation):\",\n",
    "                          file=msg_file)\n",
    "                    print(expect,\n",
    "                          file=msg_file)\n",
    "                    print(\"DB result:\",\n",
    "                          file=msg_file)\n",
    "                    print(res,\n",
    "                          file=msg_file)\n",
    "                    print(\"query\",\n",
    "                          file=msg_file)\n",
    "                    print(db_handle.to_sql(ops),\n",
    "                          file=msg_file)\n",
    "                    print(\"\", file=msg_file)\n",
    "            else:\n",
    "                res_vector[i] = 'y'\n",
    "        except Exception as ex:\n",
    "            res_vector[i] = 'n'\n",
    "            print(\"\", file=msg_file)\n",
    "            print(\"error (n)\",\n",
    "                  file=msg_file)\n",
    "            print(f'op: {op}, op_class: {op_class}, example expression: {exp}, db: {db_handle.db_model}',\n",
    "                  file=msg_file)\n",
    "            print(f\"caught: {ex}\",\n",
    "                  file=msg_file)\n",
    "            print(\"\", file=msg_file)\n",
    "    db_handle.drop_table('d')\n",
    "    return res_vector\n",
    "\n",
    "\n",
    "db_handles = [\n",
    "    data_algebra.SQLite.example_handle(),\n",
    "    data_algebra.BigQuery.example_handle(),\n",
    "    data_algebra.PostgreSQL.example_handle(),\n",
    "    data_algebra.SparkSQL.example_handle(),\n",
    "    data_algebra.MySQL.example_handle(),\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/18 08:12:42 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/01/18 08:12:42 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "with open(\"error_msgs.txt\", 'w') as msg_file:\n",
    "    for db_handle in db_handles:\n",
    "        db_test_res = test_on_db(db_handle, msg_file=msg_file)\n",
    "        op_catalog[str(db_handle.db_model)] = db_test_res\n",
    "        db_handle.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "         op  expression op_class Pandas SQLiteModel BigQueryModel  \\\n0        !=      x != y        e      y           y             y   \n1         %  row_id % q        e      y           y             n   \n2         *       x * y        e      y           y             y   \n3        **      x ** y        e      y           y             y   \n4         +       x + y        e      y           y             y   \n..      ...         ...      ...    ...         ...           ...   \n115  cumsum  x.cumsum()        w      y           y             y   \n116   ffill   z.ffill()        w      y           n             n   \n117    last    x.last()        w      y           n             n   \n118    rank    x.rank()        w      y           n             n   \n119   shift   x.shift()        w      y           y             y   \n\n    PostgreSQLModel SparkSQLModel MySQLModel version  \n0                 y             y          y   1.3.1  \n1                 n             y          n   1.3.1  \n2                 y             y          y   1.3.1  \n3                 y             y          y   1.3.1  \n4                 y             y          y   1.3.1  \n..              ...           ...        ...     ...  \n115               y             y          y   1.3.1  \n116               n             n          n   1.3.1  \n117               n             w          n   1.3.1  \n118               n             y          n   1.3.1  \n119               y             y          y   1.3.1  \n\n[120 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>op</th>\n      <th>expression</th>\n      <th>op_class</th>\n      <th>Pandas</th>\n      <th>SQLiteModel</th>\n      <th>BigQueryModel</th>\n      <th>PostgreSQLModel</th>\n      <th>SparkSQLModel</th>\n      <th>MySQLModel</th>\n      <th>version</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>!=</td>\n      <td>x != y</td>\n      <td>e</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>1.3.1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>%</td>\n      <td>row_id % q</td>\n      <td>e</td>\n      <td>y</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>n</td>\n      <td>1.3.1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>*</td>\n      <td>x * y</td>\n      <td>e</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>1.3.1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>**</td>\n      <td>x ** y</td>\n      <td>e</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>1.3.1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>+</td>\n      <td>x + y</td>\n      <td>e</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>1.3.1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>115</th>\n      <td>cumsum</td>\n      <td>x.cumsum()</td>\n      <td>w</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>1.3.1</td>\n    </tr>\n    <tr>\n      <th>116</th>\n      <td>ffill</td>\n      <td>z.ffill()</td>\n      <td>w</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>1.3.1</td>\n    </tr>\n    <tr>\n      <th>117</th>\n      <td>last</td>\n      <td>x.last()</td>\n      <td>w</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>w</td>\n      <td>n</td>\n      <td>1.3.1</td>\n    </tr>\n    <tr>\n      <th>118</th>\n      <td>rank</td>\n      <td>x.rank()</td>\n      <td>w</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>n</td>\n      <td>1.3.1</td>\n    </tr>\n    <tr>\n      <th>119</th>\n      <td>shift</td>\n      <td>x.shift()</td>\n      <td>w</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>1.3.1</td>\n    </tr>\n  </tbody>\n</table>\n<p>120 rows × 10 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op_catalog = op_catalog.sort_values(by=['op_class', 'op', 'expression'], inplace=False).reset_index(\n",
    "    drop=True, inplace=False)\n",
    "op_catalog['version'] = data_algebra.__version__\n",
    "op_catalog"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "op_catalog.to_csv('op_catalog.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "table_as_python = data_algebra.util.pandas_to_example_str(op_catalog)\n",
    "table_as_python = pretty_format_python(table_as_python)\n",
    "\n",
    "with open('op_catalog.py', 'w') as f_out:\n",
    "    print(\"\"\"\n",
    "\n",
    "import data_algebra\n",
    "\n",
    "pd = data_algebra.default_data_model.pd\n",
    "\n",
    "    \"\"\",\n",
    "          file=f_out)\n",
    "    print(\"methods_table = \" + table_as_python,\n",
    "          file=f_out)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}