{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## A catalog of [data algebra expression](https://github.com/WinVector/data_algebra) methods.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "from data_algebra.data_ops import *\n",
    "import data_algebra.SQLite\n",
    "import data_algebra.BigQuery\n",
    "import data_algebra.PostgreSQL\n",
    "import data_algebra.SparkSQL\n",
    "import data_algebra.MySQL\n",
    "from data_algebra.parse_by_lark import parse_by_lark\n",
    "import data_algebra.test_util\n",
    "import data_algebra.util\n",
    "\n",
    "\n",
    "def mk_example():\n",
    "    datetime_format = \"%Y-%m-%d %H:%M:%S\"\n",
    "    date_format = \"%Y-%m-%d\"\n",
    "    d = pd.DataFrame({\n",
    "        'row_id': [0, 1, 2, 3],\n",
    "        'a': [False, False, True, True],\n",
    "        'b': [False, True, False, True],\n",
    "        'q': [1, 1, 2, 2],\n",
    "        'x': [.1, .2, .3, .4],\n",
    "        'y': [2.4, 1.33, 1.2, 1.1],\n",
    "        'z': [1.6, None, -2.1, numpy.nan],\n",
    "        'g': ['a', 'a', 'b', 'ccc'],\n",
    "        's2': ['z', 'q', '11', 'b'],\n",
    "        \"str_datetime_col\": [\"2000-01-01 12:13:21\", \"2020-04-05 14:03:00\", \"2000-01-01 12:13:21\", \"2020-04-05 14:03:00\"],\n",
    "        \"str_date_col\": [\"2000-03-01\", \"2020-04-05\", \"2000-03-01\", \"2020-04-05\"],\n",
    "        \"datetime_col_0\": pd.to_datetime(\n",
    "            pd.Series([\"2010-01-01 12:13:21\", \"2030-04-05 14:03:00\", \"2010-01-01 12:13:21\", \"2030-04-05 14:03:00\"]),\n",
    "            format=datetime_format,\n",
    "        ),\n",
    "        \"datetime_col_1\": pd.to_datetime(\n",
    "            pd.Series([\"2010-01-01 12:11:21\", \"2030-04-06 14:03:00\", \"2010-01-01 12:11:21\", \"2030-04-06 14:03:00\"]),\n",
    "            format=date_format,\n",
    "        ),\n",
    "        \"date_col_0\": pd.to_datetime(\n",
    "            pd.Series([\"2000-01-02\", \"2035-04-05\", \"2000-01-02\", \"2035-04-05\"]),\n",
    "            format=date_format\n",
    "        ).dt.date,\n",
    "        \"date_col_1\": pd.to_datetime(\n",
    "            pd.Series([\"2000-01-02\", \"2035-05-05\", \"2000-01-02\", \"2035-05-05\"]),\n",
    "            format=date_format\n",
    "        ).dt.date,\n",
    "    })\n",
    "    return d\n",
    "\n",
    "\n",
    "def f(expression):\n",
    "    return (\n",
    "        descr(d=d)\n",
    "            .extend({'new_column': expression})\n",
    "            .select_columns(['row_id', 'new_column'])\n",
    "            .order_rows(['row_id'])\n",
    "    )\n",
    "\n",
    "\n",
    "def fg(expression):\n",
    "    return (\n",
    "        descr(d=d)\n",
    "            .extend(\n",
    "                {'new_column': expression},\n",
    "                partition_by=['g'])\n",
    "            .select_columns(['g', 'row_id', 'new_column'])\n",
    "            .order_rows(['g', 'row_id'])\n",
    "    )\n",
    "\n",
    "\n",
    "def fp(expression):\n",
    "    return (\n",
    "        descr(d=d)\n",
    "            .project(\n",
    "                {'new_column': expression},\n",
    "                group_by=['g'])\n",
    "            .order_rows(['g'])\n",
    "    )\n",
    "\n",
    "\n",
    "def fw(expression):\n",
    "    return (\n",
    "        descr(d=d)\n",
    "            .extend(\n",
    "                {'new_column': expression},\n",
    "                partition_by=['g'],\n",
    "                order_by=['row_id'])\n",
    "            .select_columns(['g', 'row_id', 'new_column'])\n",
    "            .order_rows(['g', 'row_id'])\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "   row_id      a      b  q    x     y    z    g  s2     str_datetime_col  \\\n0       0  False  False  1  0.1  2.40  1.6    a   z  2000-01-01 12:13:21   \n1       1  False   True  1  0.2  1.33  NaN    a   q  2020-04-05 14:03:00   \n2       2   True  False  2  0.3  1.20 -2.1    b  11  2000-01-01 12:13:21   \n3       3   True   True  2  0.4  1.10  NaN  ccc   b  2020-04-05 14:03:00   \n\n  str_date_col      datetime_col_0      datetime_col_1  date_col_0  date_col_1  \n0   2000-03-01 2010-01-01 12:13:21 2010-01-01 12:11:21  2000-01-02  2000-01-02  \n1   2020-04-05 2030-04-05 14:03:00 2030-04-06 14:03:00  2035-04-05  2035-05-05  \n2   2000-03-01 2010-01-01 12:13:21 2010-01-01 12:11:21  2000-01-02  2000-01-02  \n3   2020-04-05 2030-04-05 14:03:00 2030-04-06 14:03:00  2035-04-05  2035-05-05  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>row_id</th>\n      <th>a</th>\n      <th>b</th>\n      <th>q</th>\n      <th>x</th>\n      <th>y</th>\n      <th>z</th>\n      <th>g</th>\n      <th>s2</th>\n      <th>str_datetime_col</th>\n      <th>str_date_col</th>\n      <th>datetime_col_0</th>\n      <th>datetime_col_1</th>\n      <th>date_col_0</th>\n      <th>date_col_1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>1</td>\n      <td>0.1</td>\n      <td>2.40</td>\n      <td>1.6</td>\n      <td>a</td>\n      <td>z</td>\n      <td>2000-01-01 12:13:21</td>\n      <td>2000-03-01</td>\n      <td>2010-01-01 12:13:21</td>\n      <td>2010-01-01 12:11:21</td>\n      <td>2000-01-02</td>\n      <td>2000-01-02</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>False</td>\n      <td>True</td>\n      <td>1</td>\n      <td>0.2</td>\n      <td>1.33</td>\n      <td>NaN</td>\n      <td>a</td>\n      <td>q</td>\n      <td>2020-04-05 14:03:00</td>\n      <td>2020-04-05</td>\n      <td>2030-04-05 14:03:00</td>\n      <td>2030-04-06 14:03:00</td>\n      <td>2035-04-05</td>\n      <td>2035-05-05</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>True</td>\n      <td>False</td>\n      <td>2</td>\n      <td>0.3</td>\n      <td>1.20</td>\n      <td>-2.1</td>\n      <td>b</td>\n      <td>11</td>\n      <td>2000-01-01 12:13:21</td>\n      <td>2000-03-01</td>\n      <td>2010-01-01 12:13:21</td>\n      <td>2010-01-01 12:11:21</td>\n      <td>2000-01-02</td>\n      <td>2000-01-02</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>True</td>\n      <td>True</td>\n      <td>2</td>\n      <td>0.4</td>\n      <td>1.10</td>\n      <td>NaN</td>\n      <td>ccc</td>\n      <td>b</td>\n      <td>2020-04-05 14:03:00</td>\n      <td>2020-04-05</td>\n      <td>2030-04-05 14:03:00</td>\n      <td>2030-04-06 14:03:00</td>\n      <td>2035-04-05</td>\n      <td>2035-05-05</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = mk_example()\n",
    "\n",
    "d\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "data_def = {k: v for (k, v) in descr(d=d).column_map().items()}\n",
    "\n",
    "def parse(exp):\n",
    "    return parse_by_lark(exp, data_def=data_def)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "expressions = [\n",
    "    'x + y',\n",
    "    'x - y',\n",
    "    'row_id // q',\n",
    "    'row_id % q',\n",
    "    'x / y',\n",
    "    'x * y',\n",
    "    'x ** y',\n",
    "    'x == y',\n",
    "    'x > y',\n",
    "    'x >= y',\n",
    "    'x < y',\n",
    "    'x <= y',\n",
    "    'x != y',\n",
    "    '-x',\n",
    "    'not a',\n",
    "    'a & b',\n",
    "    'a and b',\n",
    "    'a | b',\n",
    "    'a or b',\n",
    "    'z.sign()',\n",
    "    'x.sin()',\n",
    "    'x.cos()',\n",
    "    'x.arcsin()',\n",
    "    'x.arccos()',\n",
    "    'x.arctan()',\n",
    "    'x.arctan2(y)',\n",
    "    'x.sinh()',\n",
    "    'x.cosh()',\n",
    "    'x.tanh()',\n",
    "    'x.arcsinh()',\n",
    "    'x.arccosh()',\n",
    "    'x.arctanh()',\n",
    "    'y.floor()',\n",
    "    'z.floor()',\n",
    "    'y.ceil()',\n",
    "    'z.ceil()',\n",
    "    'x.sum()',\n",
    "    'x.exp()',\n",
    "    'y.expm1()',\n",
    "    'x.log()',\n",
    "    'x.log10()',\n",
    "    'x.log1p()',\n",
    "    'y.mod(0.5)',\n",
    "    'y.remainder(0.5)',\n",
    "    'x.sqrt()',\n",
    "    'z.abs()',\n",
    "    'row_id.maximum(x)',\n",
    "    'row_id.minimum(x)',\n",
    "    'row_id.fmax(x)',\n",
    "    'row_id.fmin(x)',\n",
    "    'y.round()',\n",
    "    'y.around(2)',\n",
    "    'z.is_null()',\n",
    "    'z.is_bad()',\n",
    "    'z.count()',\n",
    "    'a.if_else(x, y)',\n",
    "    'row_id.is_in({1, 3})',\n",
    "    'g.concat(s2)',\n",
    "    'g %+% \"_\" %+% s2',\n",
    "    'z.coalesce(2)',\n",
    "    'z %?% 2',\n",
    "    'z.coalesce_0()',\n",
    "    'g.mapv({\"a\": 1, \"b\": 2, \"z\": 26}, 0)',\n",
    "    'y.as_int64()',\n",
    "    'y.as_str()',\n",
    "    'g.trimstr(0, 2)',\n",
    "    'datetime_col_0.datetime_to_date()',\n",
    "    'str_date_col.parse_date()',\n",
    "    'str_datetime_col.parse_datetime()',\n",
    "    'datetime_col_0.format_datetime()',\n",
    "    'date_col_0.format_date()',\n",
    "    'date_col_0.dayofweek()',\n",
    "    'date_col_0.dayofyear()',\n",
    "    'date_col_0.dayofmonth()',\n",
    "    'date_col_0.weekofyear()',\n",
    "    'date_col_0.month()',\n",
    "    'date_col_0.quarter()',\n",
    "    'date_col_0.year()',\n",
    "    'datetime_col_0.timestamp_diff(datetime_col_1)',\n",
    "    'date_col_0.date_diff(date_col_1)',\n",
    "    'date_col_1.base_Sunday()',\n",
    "]\n",
    "\n",
    "grouped_expressions = [\n",
    "    'x.sum()',\n",
    "    '(1).sum()',\n",
    "    '_ngroup()',\n",
    "    'a.all()',\n",
    "    'a.any()',\n",
    "    'x.max()',\n",
    "    'x.mean()',\n",
    "    'x.median()',\n",
    "    'x.min()',\n",
    "    'x.nunique()',\n",
    "    'x.size()',\n",
    "    '_size()',\n",
    "    '_count()',\n",
    "]\n",
    "\n",
    "project_expressions = [\n",
    "    'x.sum()',\n",
    "    '(1).sum()',\n",
    "    'a.all()',\n",
    "    'a.any()',\n",
    "    'x.max()',\n",
    "    'x.mean()',\n",
    "    'x.median()',\n",
    "    'x.min()',\n",
    "    'x.nunique()',\n",
    "    'x.size()',\n",
    "    'x.std()',\n",
    "    'x.var()',\n",
    "]\n",
    "\n",
    "windowed_expressions = [\n",
    "    'z.bfill()',\n",
    "    'z.ffill()',\n",
    "    'x.last()',\n",
    "    'x.rank()',\n",
    "    'x.cumprod()',\n",
    "    'x.cumsum()',\n",
    "    'z.cumcount()',\n",
    "    'x.cummax()',\n",
    "    'x.cummin()',\n",
    "    'x.shift()',\n",
    "    '_row_number()',\n",
    "]\n",
    "\n",
    "u_expressions = [  # not simply checkable as output varies\n",
    "    '_uniform()',\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "e_expectations = [(parse(exp).op, 'e', exp, f(exp), f(exp).transform(d)) for exp in expressions]\n",
    "g_expectations = [(parse(exp).op, 'g', exp, fg(exp), fg(exp).transform(d)) for exp in grouped_expressions]\n",
    "p_expectations = [(parse(exp).op, 'p', exp, fp(exp), fp(exp).transform(d)) for exp in project_expressions]\n",
    "w_expectations = [(parse(exp).op, 'w', exp, fw(exp), fw(exp).transform(d)) for exp in windowed_expressions]\n",
    "u_results = [(parse(exp).op, 'u', exp, f(exp), f(exp).transform(d)) for exp in u_expressions]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "with gzip.open('expr_expectations.pkl.gz', 'wb') as out_f:\n",
    "    pickle.dump(\n",
    "        {\n",
    "            'd': d,\n",
    "            'e_expectations': e_expectations,\n",
    "            'g_expectations': g_expectations,\n",
    "            'p_expectations': p_expectations,\n",
    "            'w_expectations': w_expectations,\n",
    "            'u_results': u_results,\n",
    "        },\n",
    "        out_f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/14 09:39:13 WARN Utils: Your hostname, JAMiMac.local resolves to a loopback address: 127.0.0.1; using 192.168.0.155 instead (on interface en1)\n",
      "22/01/14 09:39:13 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/01/14 09:39:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "ops_list = e_expectations + g_expectations + p_expectations + w_expectations + u_results\n",
    "\n",
    "op_catalog = pd.DataFrame({\n",
    "    'op': [op for op, op_class, exp, ops, expect in ops_list],\n",
    "    'expression': [exp for op, op_class, exp, ops, expect in ops_list],\n",
    "    'op_class': [op_class for op, op_class, exp, ops, expect in ops_list],\n",
    "})\n",
    "op_catalog['Pandas'] = 'y'\n",
    "\n",
    "\n",
    "def test_on_db(db_handle):\n",
    "    # test on db\n",
    "    res_vector = ['n'] * len(ops_list)\n",
    "    db_handle.insert_table(d, table_name='d', allow_overwrite=True)\n",
    "    for i in range(len(ops_list)):\n",
    "        op = ops_list[i][0]\n",
    "        op_class = ops_list[i][1]\n",
    "        exp = ops_list[i][2]\n",
    "        ops = ops_list[i][3]\n",
    "        expect = ops_list[i][4]\n",
    "        try:\n",
    "            res = db_handle.read_query(ops)\n",
    "            if op_class != 'u':\n",
    "                if data_algebra.test_util.equivalent_frames(res, expect):\n",
    "                    res_vector[i] = 'y'\n",
    "                else:\n",
    "                    res_vector[i] = 'w'\n",
    "                    print()\n",
    "                    print(\"difference (w)\")\n",
    "                    print(f'op: {op}, op_class: {op_class}, example expression: {exp}, db: {db_handle.db_model}')\n",
    "                    print(\"Pandas result (expectation):\")\n",
    "                    print(expect)\n",
    "                    print(\"DB result:\")\n",
    "                    print(res)\n",
    "                    print(\"query\")\n",
    "                    print(db_handle.to_sql(ops))\n",
    "                    print()\n",
    "            else:\n",
    "                res_vector[i] = 'y'\n",
    "        except Exception:\n",
    "            pass\n",
    "    db_handle.drop_table('d')\n",
    "    return res_vector\n",
    "\n",
    "\n",
    "db_handles = [\n",
    "    data_algebra.SQLite.example_handle(),\n",
    "    data_algebra.BigQuery.example_handle(),\n",
    "    data_algebra.PostgreSQL.example_handle(),\n",
    "    data_algebra.SparkSQL.example_handle(),\n",
    "    data_algebra.MySQL.example_handle(),\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "difference (w)\n",
      "op: remainder, op_class: e, example expression: y.remainder(0.5), db: SQLiteModel\n",
      "Pandas result (expectation):\n",
      "   row_id  new_column\n",
      "0       0        0.40\n",
      "1       1        0.33\n",
      "2       2        0.20\n",
      "3       3        0.10\n",
      "DB result:\n",
      "   row_id new_column\n",
      "0       0       None\n",
      "1       1       None\n",
      "2       2       None\n",
      "3       3       None\n",
      "query\n",
      "-- data_algebra SQL https://github.com/WinVector/data_algebra\n",
      "--  dialect: SQLiteModel\n",
      "--       string quote: '\n",
      "--   identifier quote: \"\n",
      "WITH\n",
      " \"table_reference_0\" AS (\n",
      "  SELECT\n",
      "   \"row_id\" ,\n",
      "   \"y\"\n",
      "  FROM\n",
      "   \"d\"\n",
      " ) ,\n",
      " \"extend_1\" AS (\n",
      "  SELECT  -- .extend({ 'new_column': 'y.remainder(0.5)'})\n",
      "   \"row_id\" ,\n",
      "   (\"y\" % 0.5) AS \"new_column\"\n",
      "  FROM\n",
      "   \"table_reference_0\"\n",
      " )\n",
      "SELECT  -- .order_rows(['row_id'])\n",
      " *\n",
      "FROM\n",
      " \"extend_1\"\n",
      "ORDER BY\n",
      " \"row_id\"\n",
      "\n",
      "\n",
      "\n",
      "difference (w)\n",
      "op: datetime_to_date, op_class: e, example expression: datetime_col_0.datetime_to_date(), db: SQLiteModel\n",
      "Pandas result (expectation):\n",
      "   row_id  new_column\n",
      "0       0  2010-01-01\n",
      "1       1  2030-04-05\n",
      "2       2  2010-01-01\n",
      "3       3  2030-04-05\n",
      "DB result:\n",
      "   row_id  new_column\n",
      "0       0  2010-01-01\n",
      "1       1  2030-04-05\n",
      "2       2  2010-01-01\n",
      "3       3  2030-04-05\n",
      "query\n",
      "-- data_algebra SQL https://github.com/WinVector/data_algebra\n",
      "--  dialect: SQLiteModel\n",
      "--       string quote: '\n",
      "--   identifier quote: \"\n",
      "WITH\n",
      " \"table_reference_0\" AS (\n",
      "  SELECT\n",
      "   \"row_id\" ,\n",
      "   \"datetime_col_0\"\n",
      "  FROM\n",
      "   \"d\"\n",
      " ) ,\n",
      " \"extend_1\" AS (\n",
      "  SELECT  -- .extend({ 'new_column': 'datetime_col_0.datetime_to_date()'})\n",
      "   \"row_id\" ,\n",
      "   DATE(\"datetime_col_0\") AS \"new_column\"\n",
      "  FROM\n",
      "   \"table_reference_0\"\n",
      " )\n",
      "SELECT  -- .order_rows(['row_id'])\n",
      " *\n",
      "FROM\n",
      " \"extend_1\"\n",
      "ORDER BY\n",
      " \"row_id\"\n",
      "\n",
      "\n",
      "\n",
      "difference (w)\n",
      "op: _count, op_class: g, example expression: _count(), db: SQLiteModel\n",
      "Pandas result (expectation):\n",
      "     g  row_id  new_column\n",
      "0    a       0           1\n",
      "1    a       1           2\n",
      "2    b       2           1\n",
      "3  ccc       3           1\n",
      "DB result:\n",
      "     g  row_id  new_column\n",
      "0    a       0           2\n",
      "1    a       1           2\n",
      "2    b       2           1\n",
      "3  ccc       3           1\n",
      "query\n",
      "-- data_algebra SQL https://github.com/WinVector/data_algebra\n",
      "--  dialect: SQLiteModel\n",
      "--       string quote: '\n",
      "--   identifier quote: \"\n",
      "WITH\n",
      " \"table_reference_0\" AS (\n",
      "  SELECT\n",
      "   \"row_id\" ,\n",
      "   \"g\"\n",
      "  FROM\n",
      "   \"d\"\n",
      " ) ,\n",
      " \"extend_1\" AS (\n",
      "  SELECT  -- .extend({ 'new_column': '_count()'}, partition_by=['g'])\n",
      "   \"g\" ,\n",
      "   \"row_id\" ,\n",
      "   SUM(1) OVER ( PARTITION BY \"g\"  )  AS \"new_column\"\n",
      "  FROM\n",
      "   \"table_reference_0\"\n",
      " )\n",
      "SELECT  -- .order_rows(['g', 'row_id'])\n",
      " *\n",
      "FROM\n",
      " \"extend_1\"\n",
      "ORDER BY\n",
      " \"g\" ,\n",
      " \"row_id\"\n",
      "\n",
      "\n",
      "\n",
      "difference (w)\n",
      "op: _count, op_class: g, example expression: _count(), db: BigQueryModel\n",
      "Pandas result (expectation):\n",
      "     g  row_id  new_column\n",
      "0    a       0           1\n",
      "1    a       1           2\n",
      "2    b       2           1\n",
      "3  ccc       3           1\n",
      "DB result:\n",
      "     g  row_id  new_column\n",
      "0    a       0           2\n",
      "1    a       1           2\n",
      "2    b       2           1\n",
      "3  ccc       3           1\n",
      "query\n",
      "-- data_algebra SQL https://github.com/WinVector/data_algebra\n",
      "--  dialect: BigQueryModel\n",
      "--       string quote: \"\n",
      "--   identifier quote: `\n",
      "WITH\n",
      " `table_reference_0` AS (\n",
      "  SELECT\n",
      "   `row_id` ,\n",
      "   `g`\n",
      "  FROM\n",
      "   `data-algebra-test.test_1.d`\n",
      " ) ,\n",
      " `extend_1` AS (\n",
      "  SELECT  -- .extend({ 'new_column': '_count()'}, partition_by=['g'])\n",
      "   `g` ,\n",
      "   `row_id` ,\n",
      "   SUM(1) OVER ( PARTITION BY `g`  )  AS `new_column`\n",
      "  FROM\n",
      "   `table_reference_0`\n",
      " )\n",
      "SELECT  -- .order_rows(['g', 'row_id'])\n",
      " *\n",
      "FROM\n",
      " `extend_1`\n",
      "ORDER BY\n",
      " `g` ,\n",
      " `row_id`\n",
      "\n",
      "\n",
      "\n",
      "difference (w)\n",
      "op: weekofyear, op_class: e, example expression: date_col_0.weekofyear(), db: PostgreSQLModel\n",
      "Pandas result (expectation):\n",
      "   row_id  new_column\n",
      "0       0           1\n",
      "1       1          13\n",
      "2       2           1\n",
      "3       3          13\n",
      "DB result:\n",
      "   row_id  new_column\n",
      "0       0        52.0\n",
      "1       1        14.0\n",
      "2       2        52.0\n",
      "3       3        14.0\n",
      "query\n",
      "-- data_algebra SQL https://github.com/WinVector/data_algebra\n",
      "--  dialect: PostgreSQLModel\n",
      "--       string quote: '\n",
      "--   identifier quote: \"\n",
      "WITH\n",
      " \"table_reference_0\" AS (\n",
      "  SELECT\n",
      "   \"row_id\" ,\n",
      "   \"date_col_0\"\n",
      "  FROM\n",
      "   \"d\"\n",
      " ) ,\n",
      " \"extend_1\" AS (\n",
      "  SELECT  -- .extend({ 'new_column': 'date_col_0.weekofyear()'})\n",
      "   \"row_id\" ,\n",
      "   EXTRACT(WEEK FROM \"date_col_0\") AS \"new_column\"\n",
      "  FROM\n",
      "   \"table_reference_0\"\n",
      " )\n",
      "SELECT  -- .order_rows(['row_id'])\n",
      " *\n",
      "FROM\n",
      " \"extend_1\"\n",
      "ORDER BY\n",
      " \"row_id\"\n",
      "\n",
      "\n",
      "\n",
      "difference (w)\n",
      "op: _count, op_class: g, example expression: _count(), db: PostgreSQLModel\n",
      "Pandas result (expectation):\n",
      "     g  row_id  new_column\n",
      "0    a       0           1\n",
      "1    a       1           2\n",
      "2    b       2           1\n",
      "3  ccc       3           1\n",
      "DB result:\n",
      "     g  row_id  new_column\n",
      "0    a       0           2\n",
      "1    a       1           2\n",
      "2    b       2           1\n",
      "3  ccc       3           1\n",
      "query\n",
      "-- data_algebra SQL https://github.com/WinVector/data_algebra\n",
      "--  dialect: PostgreSQLModel\n",
      "--       string quote: '\n",
      "--   identifier quote: \"\n",
      "WITH\n",
      " \"table_reference_0\" AS (\n",
      "  SELECT\n",
      "   \"row_id\" ,\n",
      "   \"g\"\n",
      "  FROM\n",
      "   \"d\"\n",
      " ) ,\n",
      " \"extend_1\" AS (\n",
      "  SELECT  -- .extend({ 'new_column': '_count()'}, partition_by=['g'])\n",
      "   \"g\" ,\n",
      "   \"row_id\" ,\n",
      "   SUM(1) OVER ( PARTITION BY \"g\"  )  AS \"new_column\"\n",
      "  FROM\n",
      "   \"table_reference_0\"\n",
      " )\n",
      "SELECT  -- .order_rows(['g', 'row_id'])\n",
      " *\n",
      "FROM\n",
      " \"extend_1\"\n",
      "ORDER BY\n",
      " \"g\" ,\n",
      " \"row_id\"\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "difference (w)\n",
      "op: floor, op_class: e, example expression: z.floor(), db: SparkSQLModel\n",
      "Pandas result (expectation):\n",
      "   row_id  new_column\n",
      "0       0         1.0\n",
      "1       1         NaN\n",
      "2       2        -3.0\n",
      "3       3         NaN\n",
      "DB result:\n",
      "   row_id  new_column\n",
      "0       0           1\n",
      "1       1           0\n",
      "2       2          -3\n",
      "3       3           0\n",
      "query\n",
      "-- data_algebra SQL https://github.com/WinVector/data_algebra\n",
      "--  dialect: SparkSQLModel\n",
      "--       string quote: \"\n",
      "--   identifier quote: `\n",
      "WITH\n",
      " `table_reference_0` AS (\n",
      "  SELECT\n",
      "   `row_id` ,\n",
      "   `z`\n",
      "  FROM\n",
      "   `d`\n",
      " ) ,\n",
      " `extend_1` AS (\n",
      "  SELECT  -- .extend({ 'new_column': 'z.floor()'})\n",
      "   `row_id` ,\n",
      "   FLOOR(`z`) AS `new_column`\n",
      "  FROM\n",
      "   `table_reference_0`\n",
      " )\n",
      "SELECT  -- .order_rows(['row_id'])\n",
      " *\n",
      "FROM\n",
      " `extend_1`\n",
      "ORDER BY\n",
      " `row_id`\n",
      "\n",
      "\n",
      "\n",
      "difference (w)\n",
      "op: ceil, op_class: e, example expression: z.ceil(), db: SparkSQLModel\n",
      "Pandas result (expectation):\n",
      "   row_id  new_column\n",
      "0       0         2.0\n",
      "1       1         NaN\n",
      "2       2        -2.0\n",
      "3       3         NaN\n",
      "DB result:\n",
      "   row_id  new_column\n",
      "0       0           2\n",
      "1       1           0\n",
      "2       2          -2\n",
      "3       3           0\n",
      "query\n",
      "-- data_algebra SQL https://github.com/WinVector/data_algebra\n",
      "--  dialect: SparkSQLModel\n",
      "--       string quote: \"\n",
      "--   identifier quote: `\n",
      "WITH\n",
      " `table_reference_0` AS (\n",
      "  SELECT\n",
      "   `row_id` ,\n",
      "   `z`\n",
      "  FROM\n",
      "   `d`\n",
      " ) ,\n",
      " `extend_1` AS (\n",
      "  SELECT  -- .extend({ 'new_column': 'z.ceil()'})\n",
      "   `row_id` ,\n",
      "   CEILING(`z`) AS `new_column`\n",
      "  FROM\n",
      "   `table_reference_0`\n",
      " )\n",
      "SELECT  -- .order_rows(['row_id'])\n",
      " *\n",
      "FROM\n",
      " `extend_1`\n",
      "ORDER BY\n",
      " `row_id`\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/14 09:41:52 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/01/14 09:41:52 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "difference (w)\n",
      "op: is_null, op_class: e, example expression: z.is_null(), db: SparkSQLModel\n",
      "Pandas result (expectation):\n",
      "   row_id  new_column\n",
      "0       0       False\n",
      "1       1        True\n",
      "2       2       False\n",
      "3       3        True\n",
      "DB result:\n",
      "   row_id  new_column\n",
      "0       0       False\n",
      "1       1       False\n",
      "2       2       False\n",
      "3       3       False\n",
      "query\n",
      "-- data_algebra SQL https://github.com/WinVector/data_algebra\n",
      "--  dialect: SparkSQLModel\n",
      "--       string quote: \"\n",
      "--   identifier quote: `\n",
      "WITH\n",
      " `table_reference_0` AS (\n",
      "  SELECT\n",
      "   `row_id` ,\n",
      "   `z`\n",
      "  FROM\n",
      "   `d`\n",
      " ) ,\n",
      " `extend_1` AS (\n",
      "  SELECT  -- .extend({ 'new_column': 'z.is_null()'})\n",
      "   `row_id` ,\n",
      "   (`z` IS NULL) AS `new_column`\n",
      "  FROM\n",
      "   `table_reference_0`\n",
      " )\n",
      "SELECT  -- .order_rows(['row_id'])\n",
      " *\n",
      "FROM\n",
      " `extend_1`\n",
      "ORDER BY\n",
      " `row_id`\n",
      "\n",
      "\n",
      "\n",
      "difference (w)\n",
      "op: count, op_class: e, example expression: z.count(), db: SparkSQLModel\n",
      "Pandas result (expectation):\n",
      "   row_id  new_column\n",
      "0       0           2\n",
      "1       1           2\n",
      "2       2           2\n",
      "3       3           2\n",
      "DB result:\n",
      "   row_id  new_column\n",
      "0       0           4\n",
      "1       1           4\n",
      "2       2           4\n",
      "3       3           4\n",
      "query\n",
      "-- data_algebra SQL https://github.com/WinVector/data_algebra\n",
      "--  dialect: SparkSQLModel\n",
      "--       string quote: \"\n",
      "--   identifier quote: `\n",
      "WITH\n",
      " `table_reference_0` AS (\n",
      "  SELECT\n",
      "   `row_id` ,\n",
      "   `z`\n",
      "  FROM\n",
      "   `d`\n",
      " ) ,\n",
      " `extend_1` AS (\n",
      "  SELECT  -- .extend({ 'new_column': 'z.count()'}, partition_by=1)\n",
      "   `row_id` ,\n",
      "   SUM(CASE WHEN `z` IS NOT NULL THEN 1 ELSE 0 END) OVER (  )  AS `new_column`\n",
      "  FROM\n",
      "   `table_reference_0`\n",
      " )\n",
      "SELECT  -- .order_rows(['row_id'])\n",
      " *\n",
      "FROM\n",
      " `extend_1`\n",
      "ORDER BY\n",
      " `row_id`\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/14 09:41:54 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/01/14 09:41:54 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "difference (w)\n",
      "op: weekofyear, op_class: e, example expression: date_col_0.weekofyear(), db: SparkSQLModel\n",
      "Pandas result (expectation):\n",
      "   row_id  new_column\n",
      "0       0           1\n",
      "1       1          13\n",
      "2       2           1\n",
      "3       3          13\n",
      "DB result:\n",
      "   row_id  new_column\n",
      "0       0          52\n",
      "1       1          14\n",
      "2       2          52\n",
      "3       3          14\n",
      "query\n",
      "-- data_algebra SQL https://github.com/WinVector/data_algebra\n",
      "--  dialect: SparkSQLModel\n",
      "--       string quote: \"\n",
      "--   identifier quote: `\n",
      "WITH\n",
      " `table_reference_0` AS (\n",
      "  SELECT\n",
      "   `row_id` ,\n",
      "   `date_col_0`\n",
      "  FROM\n",
      "   `d`\n",
      " ) ,\n",
      " `extend_1` AS (\n",
      "  SELECT  -- .extend({ 'new_column': 'date_col_0.weekofyear()'})\n",
      "   `row_id` ,\n",
      "   EXTRACT(WEEK FROM `date_col_0`) AS `new_column`\n",
      "  FROM\n",
      "   `table_reference_0`\n",
      " )\n",
      "SELECT  -- .order_rows(['row_id'])\n",
      " *\n",
      "FROM\n",
      " `extend_1`\n",
      "ORDER BY\n",
      " `row_id`\n",
      "\n",
      "\n",
      "\n",
      "difference (w)\n",
      "op: _count, op_class: g, example expression: _count(), db: SparkSQLModel\n",
      "Pandas result (expectation):\n",
      "     g  row_id  new_column\n",
      "0    a       0           1\n",
      "1    a       1           2\n",
      "2    b       2           1\n",
      "3  ccc       3           1\n",
      "DB result:\n",
      "     g  row_id  new_column\n",
      "0    a       0           2\n",
      "1    a       1           2\n",
      "2    b       2           1\n",
      "3  ccc       3           1\n",
      "query\n",
      "-- data_algebra SQL https://github.com/WinVector/data_algebra\n",
      "--  dialect: SparkSQLModel\n",
      "--       string quote: \"\n",
      "--   identifier quote: `\n",
      "WITH\n",
      " `table_reference_0` AS (\n",
      "  SELECT\n",
      "   `row_id` ,\n",
      "   `g`\n",
      "  FROM\n",
      "   `d`\n",
      " ) ,\n",
      " `extend_1` AS (\n",
      "  SELECT  -- .extend({ 'new_column': '_count()'}, partition_by=['g'])\n",
      "   `g` ,\n",
      "   `row_id` ,\n",
      "   SUM(1) OVER ( PARTITION BY `g`  )  AS `new_column`\n",
      "  FROM\n",
      "   `table_reference_0`\n",
      " )\n",
      "SELECT  -- .order_rows(['g', 'row_id'])\n",
      " *\n",
      "FROM\n",
      " `extend_1`\n",
      "ORDER BY\n",
      " `g` ,\n",
      " `row_id`\n",
      "\n",
      "\n",
      "\n",
      "difference (w)\n",
      "op: last, op_class: w, example expression: x.last(), db: SparkSQLModel\n",
      "Pandas result (expectation):\n",
      "     g  row_id  new_column\n",
      "0    a       0         0.2\n",
      "1    a       1         0.2\n",
      "2    b       2         0.3\n",
      "3  ccc       3         0.4\n",
      "DB result:\n",
      "     g  row_id  new_column\n",
      "0    a       0         0.1\n",
      "1    a       1         0.2\n",
      "2    b       2         0.3\n",
      "3  ccc       3         0.4\n",
      "query\n",
      "-- data_algebra SQL https://github.com/WinVector/data_algebra\n",
      "--  dialect: SparkSQLModel\n",
      "--       string quote: \"\n",
      "--   identifier quote: `\n",
      "WITH\n",
      " `table_reference_0` AS (\n",
      "  SELECT\n",
      "   `row_id` ,\n",
      "   `x` ,\n",
      "   `g`\n",
      "  FROM\n",
      "   `d`\n",
      " ) ,\n",
      " `extend_1` AS (\n",
      "  SELECT  -- .extend({ 'new_column': 'x.last()'}, partition_by=['g'], order_by=['row_id'])\n",
      "   `g` ,\n",
      "   `row_id` ,\n",
      "   LAST(`x`) OVER ( PARTITION BY `g` ORDER BY `row_id`  )  AS `new_column`\n",
      "  FROM\n",
      "   `table_reference_0`\n",
      " )\n",
      "SELECT  -- .order_rows(['g', 'row_id'])\n",
      " *\n",
      "FROM\n",
      " `extend_1`\n",
      "ORDER BY\n",
      " `g` ,\n",
      " `row_id`\n",
      "\n",
      "\n",
      "\n",
      "difference (w)\n",
      "op: _count, op_class: g, example expression: _count(), db: MySQLModel\n",
      "Pandas result (expectation):\n",
      "     g  row_id  new_column\n",
      "0    a       0           1\n",
      "1    a       1           2\n",
      "2    b       2           1\n",
      "3  ccc       3           1\n",
      "DB result:\n",
      "     g  row_id  new_column\n",
      "0    a       0         2.0\n",
      "1    a       1         2.0\n",
      "2    b       2         1.0\n",
      "3  ccc       3         1.0\n",
      "query\n",
      "-- data_algebra SQL https://github.com/WinVector/data_algebra\n",
      "--  dialect: MySQLModel\n",
      "--       string quote: '\n",
      "--   identifier quote: `\n",
      "WITH\n",
      " `table_reference_0` AS (\n",
      "  SELECT\n",
      "   `row_id` ,\n",
      "   `g`\n",
      "  FROM\n",
      "   `d`\n",
      " ) ,\n",
      " `extend_1` AS (\n",
      "  SELECT  -- .extend({ 'new_column': '_count()'}, partition_by=['g'])\n",
      "   `g` ,\n",
      "   `row_id` ,\n",
      "   SUM(1) OVER ( PARTITION BY `g`  )  AS `new_column`\n",
      "  FROM\n",
      "   `table_reference_0`\n",
      " )\n",
      "SELECT  -- .order_rows(['g', 'row_id'])\n",
      " *\n",
      "FROM\n",
      " `extend_1`\n",
      "ORDER BY\n",
      " `g` ,\n",
      " `row_id`\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "for db_handle in db_handles:\n",
    "    db_test_res = test_on_db(db_handle)\n",
    "    op_catalog[str(db_handle.db_model)] = db_test_res\n",
    "    db_handle.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "         op  expression op_class Pandas SQLiteModel BigQueryModel  \\\n0        !=      x != y        e      y           y             y   \n1         %  row_id % q        e      y           y             n   \n2         *       x * y        e      y           y             y   \n3        **      x ** y        e      y           y             y   \n4         +       x + y        e      y           y             y   \n..      ...         ...      ...    ...         ...           ...   \n113  cumsum  x.cumsum()        w      y           y             y   \n114   ffill   z.ffill()        w      y           n             n   \n115    last    x.last()        w      y           n             n   \n116    rank    x.rank()        w      y           n             n   \n117   shift   x.shift()        w      y           y             y   \n\n    PostgreSQLModel SparkSQLModel MySQLModel version  \n0                 y             y          y   1.3.0  \n1                 n             y          n   1.3.0  \n2                 y             y          y   1.3.0  \n3                 y             y          y   1.3.0  \n4                 y             y          y   1.3.0  \n..              ...           ...        ...     ...  \n113               y             y          y   1.3.0  \n114               n             n          n   1.3.0  \n115               n             w          n   1.3.0  \n116               n             y          n   1.3.0  \n117               y             y          y   1.3.0  \n\n[118 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>op</th>\n      <th>expression</th>\n      <th>op_class</th>\n      <th>Pandas</th>\n      <th>SQLiteModel</th>\n      <th>BigQueryModel</th>\n      <th>PostgreSQLModel</th>\n      <th>SparkSQLModel</th>\n      <th>MySQLModel</th>\n      <th>version</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>!=</td>\n      <td>x != y</td>\n      <td>e</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>1.3.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>%</td>\n      <td>row_id % q</td>\n      <td>e</td>\n      <td>y</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>n</td>\n      <td>1.3.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>*</td>\n      <td>x * y</td>\n      <td>e</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>1.3.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>**</td>\n      <td>x ** y</td>\n      <td>e</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>1.3.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>+</td>\n      <td>x + y</td>\n      <td>e</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>1.3.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>113</th>\n      <td>cumsum</td>\n      <td>x.cumsum()</td>\n      <td>w</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>1.3.0</td>\n    </tr>\n    <tr>\n      <th>114</th>\n      <td>ffill</td>\n      <td>z.ffill()</td>\n      <td>w</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>1.3.0</td>\n    </tr>\n    <tr>\n      <th>115</th>\n      <td>last</td>\n      <td>x.last()</td>\n      <td>w</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>w</td>\n      <td>n</td>\n      <td>1.3.0</td>\n    </tr>\n    <tr>\n      <th>116</th>\n      <td>rank</td>\n      <td>x.rank()</td>\n      <td>w</td>\n      <td>y</td>\n      <td>n</td>\n      <td>n</td>\n      <td>n</td>\n      <td>y</td>\n      <td>n</td>\n      <td>1.3.0</td>\n    </tr>\n    <tr>\n      <th>117</th>\n      <td>shift</td>\n      <td>x.shift()</td>\n      <td>w</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>y</td>\n      <td>1.3.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>118 rows × 10 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op_catalog = op_catalog.sort_values(by=['op_class', 'op', 'expression'], inplace=False).reset_index(\n",
    "    drop=True, inplace=False)\n",
    "op_catalog['version'] = data_algebra.__version__\n",
    "op_catalog"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "op_catalog.to_csv('op_catalog.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "table_as_python = data_algebra.util.pandas_to_example_str(op_catalog)\n",
    "table_as_python = pretty_format_python(table_as_python)\n",
    "\n",
    "with open('op_catalog.py', 'w') as f_out:\n",
    "    print(\"\"\"\n",
    "\n",
    "import data_algebra\n",
    "\n",
    "pd = data_algebra.default_data_model.pd\n",
    "\n",
    "    \"\"\", file=f_out)\n",
    "    print(\"methods_table = \" + table_as_python, file=f_out)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}