{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Using the data algebra for Statistics and Data Science\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This is an intermediate level example of using the [data algebra](https://github.com/WinVector/data_algebra) to translate a statistical method into an implementation that works both with Pandas and in databases.\n",
    "\n",
    "This example turns out to be fairly non-trivial, as it involves:\n",
    "\n",
    "  * Aggregating data.\n",
    "  * Combining the aggregations either through a \"join results\" strategy.\n",
    "  * Re-shaping records to move from multi row records to single row records.\n",
    "\n",
    "This many steps can be daunting. The guiding principle is: decompose into sub-problems, solve those, and then compose the pieces into a working solution. The data algebra supports this strategy as it is optimized to build up data processing pipelines from smaller pieces and is optimized for re-use and testing.\n",
    "\n",
    "### The problem\n",
    "\n",
    "We will demonstrate using the data algebra to solve a statistical problem: computing a difference in means in terms of a non-pooled standard deviation. What makes it a challenge is: we want to do this quickly per-group for possibly very many groups.\n",
    "\n",
    "First we set up some example data in Python using Numpy and Pandas."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy.random\n",
    "import pandas\n",
    "\n",
    "from data_algebra.data_ops import *\n",
    "from data_algebra.cdata import *\n",
    "import data_algebra.BigQuery\n",
    "import data_algebra.test_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "  group     value sensor\n0     a  0.051306     s2\n1     a  0.700005     s2\n2     a -1.022481     s2\n3     b  1.862029     s1\n4     c -1.173817     s2",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>group</th>\n      <th>value</th>\n      <th>sensor</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>a</td>\n      <td>0.051306</td>\n      <td>s2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>a</td>\n      <td>0.700005</td>\n      <td>s2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>a</td>\n      <td>-1.022481</td>\n      <td>s2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>b</td>\n      <td>1.862029</td>\n      <td>s1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>c</td>\n      <td>-1.173817</td>\n      <td>s2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build synthetic example data\n",
    "\n",
    "# seed the pseudo-random generator for repeatability\n",
    "numpy.random.seed(1999)\n",
    "\n",
    "# choose our simulated number of observations\n",
    "n_obs = 1000\n",
    "\n",
    "d = pandas.DataFrame({\n",
    "    'group': numpy.random.choice(['a', 'b', 'c'], size=n_obs, replace=True),\n",
    "    'value': numpy.random.normal(0, 1, size=n_obs),\n",
    "    'sensor': numpy.random.choice(['s1', 's2'], size=n_obs, replace=True),\n",
    "})\n",
    "# make the b group have an actual difference in means of s1 versus s2\n",
    "group_b_sensor_s2_rows = (d['group'] == 'b') & (d['sensor'] == 's2')\n",
    "d.loc[group_b_sensor_s2_rows, 'value'] = d.loc[group_b_sensor_s2_rows, 'value']  + 0.5\n",
    "\n",
    "d.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The data is synthetic. What is modeling is taking measurements from different groups using two different sensors.\n",
    "\n",
    "We want to see, for each group if the empirically observed difference in means in the values recorded by sensor `s1` and sensor `s2` are different in an interesting way. By our construction of the synthetic data there is a significant difference in group `b`, and not in any other group.\n",
    "\n",
    "This is essentially an [ANOVA](https://en.wikipedia.org/wiki/Analysis_of_variance) and [T-test](https://en.wikipedia.org/wiki/Student%27s_t-test) type of question, where we define interesting as the observed difference being rare under a null hypothesis such as the means and variance being shared between `s1` and `s2` sensors per group.\n",
    "\n",
    "\n",
    "## The Statistical Package Approach\n",
    "\n",
    "Before using the data algebra, let us do this the standard way: using a pre-packaged solution."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "  group         t  significance\n0     a -1.139708      0.255263\n1     b -3.452261      0.000630\n2     c  0.467327      0.640554",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>group</th>\n      <th>t</th>\n      <th>significance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>a</td>\n      <td>-1.139708</td>\n      <td>0.255263</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>b</td>\n      <td>-3.452261</td>\n      <td>0.000630</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>c</td>\n      <td>0.467327</td>\n      <td>0.640554</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.stats\n",
    "\n",
    "groups = list(set(d['group']))\n",
    "groups.sort()\n",
    "d_grouped = d.groupby(['group'])\n",
    "\n",
    "def f(g):\n",
    "    d_sub = d_grouped.get_group(g)\n",
    "    v_s1 = d_sub.loc[d_sub['sensor'] == 's1', 'value']\n",
    "    v_s2 = d_sub.loc[d_sub['sensor'] == 's2', 'value']\n",
    "    res_g = scipy.stats.ttest_ind(v_s1, v_s2)\n",
    "    return pandas.DataFrame({\n",
    "        'group': [g],\n",
    "        't': [res_g.statistic],\n",
    "        'significance': [res_g.pvalue],\n",
    "    })\n",
    "\n",
    "group_stats = [f(g) for g in groups]\n",
    "group_stats = pandas.concat(group_stats).reset_index(inplace=False, drop=True)\n",
    "\n",
    "group_stats"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For our example let's pursue this calculation by hand. Our quantity of interest is going to be: for each group we want to estimate `t = ((s1 estimate) - s2 estimate)) / (var(s1 estimate) + var(s2 estimate)).sqrt()`, where `(si estimte) = mean(si)`. This estimate is using the fact that, for independent processes variances are additive.\n",
    "\n",
    "When `|t|` is large (say 2 or 3), we consider the observed difference to be unlikely under the null hypothesis that the true means or expected values of `s1` and `s2` sensor are identical per group. The reasoning being under the null hypothesis (and under fairly mild additional conditions and with enough data), `t` with be nearly [Student-t distributed](https://en.wikipedia.org/wiki/Student%27s_t-distribution) where absolute values as large as 2 or 3 being somewhat rare.\n",
    "\n",
    "So let's estimate `t` using the data algebra."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The Solution\n",
    "\n",
    "The strategy is to break the calculation down into smaller solvable steps. The data algebra is essentially a coding of [Codd's relational algebra](https://en.wikipedia.org/wiki/Relational_algebra) in Python. This is just the thesis that if one learns a few primary data transforms, then many data processing tasks can be effectively written in terms of these operations. The operations are typically:\n",
    "\n",
    "\n",
    "   * Adding a column as function of other columns. That is for each row values are combined to create a new value. This often called an extension.\n",
    "   * Computing an aggregation such as mean, max in one column controlled by a specification of which rows are to be grouped together. This is typically called projection if we want exactly one row result per group or a \"window function\" if we want one result row per input row.\n",
    "   * Joining rows from two data frames that match on particular key columns. This is a powerful method of mapped lookup and cross-product formation.\n",
    "\n",
    "In terms of these operators we want new columns such as `mean(s1 values)`, `mean(s2 values)`, and so on, to be calculated per group. The organizing idea is:\n",
    "\n",
    "> Imagine some columns such that if these columns were already in your data frame, then the calculation would be easy to finish. Then add these columns to your data frame.\n",
    "\n",
    "Let's do that using the data algebra.\n",
    "\n",
    "### Adding Some Columns\n",
    "\n",
    "First we specify the operations we want to perform. The wish we are trying to satisfy is: \"the calculation would be much easier we already knew the per sensor and group standard deviations and group sizes\". This can be written a \"project\" operation partitioned by our grouping columns `group` and `sensor`.\n",
    "\n",
    "Our definition of operators is as follows. We start with `describe_table()` which build a description of the column structure of our data frame `d`. We then call `.extend()` on this object to specify new columns (`group_sd` and `group_size`) we want produced. The `partition_by` specifies which set of rows go into each calculation. We also add more steps to combine these columns to get the per-group variances. Notice the later steps don't use a partition to be specified, as we can safely calculate per row. The rule is: each extend is separated to use only values that are available before the step.\n",
    "\n",
    "This is easiest just to see this in action."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# define our operators\n",
    "td = descr(d=d)\n",
    "ops_var = (\n",
    "    td\n",
    "        .project(\n",
    "            {\n",
    "                'group_sensor_var': 'value.var()',  # estimate variance of items\n",
    "                'group_sensor_mean': 'value.mean()',  # estimate mean of items\n",
    "                'group_sensor_n': '(1).sum()',   # sample sizes\n",
    "            },\n",
    "            group_by=['group', 'sensor'])\n",
    "        .extend(  # get the variance of the mean estimate\n",
    "            {'group_sensor_est_var': 'group_sensor_var / group_sensor_n'})\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The operations we used are:\n",
    "\n",
    "\n",
    "  * `extend()`: add new columns to current rows. This can work either without a partition, where each calculation is performed among values in each row. Or this can work with a partition, where values are aggregated across groups of rows, but still written into the original rows. In an `extend()` the calculation is specified as a dictionary of new column values mapping to the quoted expressions to calculate the values. The expression grammar is similar to Python/Numpy/Pandas, with a good number of methods available. Each extend can only refer to values that already exist, this is to prevent confusion as to which values are in which columns during calculation.\n",
    "  * `project()` is a grouped operation where each group of rows is replaced by a single row. The grouping columns are copied into the new row, so they don't have to be specified. Any other columns must be created by calculations.\n",
    "\n",
    "\n",
    "The types of operators will be familiar to [dplyr]( https://CRAN.R-project.org/package=dplyr) users. However, they originally come from Codd, and this style of emphasis on composition was prototyped in [rqdatatable](https://CRAN.R-project.org/package=rqdatatable). A complete method list can be found [here](https://github.com/WinVector/data_algebra/blob/main/Examples/Methods/op_catalog.csv). A general introduction is found [here](https://github.com/WinVector/data_algebra).\n",
    "\n",
    "Our working values look like the following if we apply the operations we have up to now."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "  group sensor  group_sensor_var  group_sensor_mean  group_sensor_n  \\\n0     a     s1          0.966323          -0.103881             134   \n1     a     s2          0.861280           0.018839             187   \n2     b     s1          0.890383           0.097989             161   \n3     b     s2          0.992986           0.470291             163   \n4     c     s1          0.977829           0.069197             166   \n5     c     s2          1.176182           0.017453             189   \n\n   group_sensor_est_var  \n0              0.007211  \n1              0.004606  \n2              0.005530  \n3              0.006092  \n4              0.005891  \n5              0.006223  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>group</th>\n      <th>sensor</th>\n      <th>group_sensor_var</th>\n      <th>group_sensor_mean</th>\n      <th>group_sensor_n</th>\n      <th>group_sensor_est_var</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>a</td>\n      <td>s1</td>\n      <td>0.966323</td>\n      <td>-0.103881</td>\n      <td>134</td>\n      <td>0.007211</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>a</td>\n      <td>s2</td>\n      <td>0.861280</td>\n      <td>0.018839</td>\n      <td>187</td>\n      <td>0.004606</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>b</td>\n      <td>s1</td>\n      <td>0.890383</td>\n      <td>0.097989</td>\n      <td>161</td>\n      <td>0.005530</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>b</td>\n      <td>s2</td>\n      <td>0.992986</td>\n      <td>0.470291</td>\n      <td>163</td>\n      <td>0.006092</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>c</td>\n      <td>s1</td>\n      <td>0.977829</td>\n      <td>0.069197</td>\n      <td>166</td>\n      <td>0.005891</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>c</td>\n      <td>s2</td>\n      <td>1.176182</td>\n      <td>0.017453</td>\n      <td>189</td>\n      <td>0.006223</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply our operators to our data frame d\n",
    "ops_var.transform(d)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The `transform()` implementation is modular and is intended to eventually support other realizations of Pandas style APIs. Prospects include Dask, datatable, RAPIDS; but we have not started development on these adapters. To support his prospect there is only one explicit reference to Pandas in the package, and that reference can be overridden by the user.\n",
    "\n",
    "## Combining Rows to Get Results\n",
    "\n",
    "We can now see the sensors seem to differ more in group `b` than in the other groups. Let's finish the calculation and quantify this. We now have the issue of needing values from specific pairs of rows. The simplest way to work around this is to get all the values we want into a single row and then work forward.\n",
    "\n",
    "What we mean is we wish to take a record that looks like the following."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "  group sensor  group_sensor_mean  group_sensor_est_var\n0     a     s1          -0.103881              0.007211\n1     a     s2           0.018839              0.004606",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>group</th>\n      <th>sensor</th>\n      <th>group_sensor_mean</th>\n      <th>group_sensor_est_var</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>a</td>\n      <td>s1</td>\n      <td>-0.103881</td>\n      <td>0.007211</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>a</td>\n      <td>s2</td>\n      <td>0.018839</td>\n      <td>0.004606</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pandas.DataFrame({\n",
    "    'group': ['a', 'a'],\n",
    "    'sensor': ['s1', 's2'],\n",
    "    'group_sensor_mean': [-0.103881, 0.018839],\n",
    "    'group_sensor_est_var': [0.007211, 0.004606],\n",
    "})\n",
    "\n",
    "a"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "And transform it into a single row such as the following."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "  group  group_sensor_mean_s1  group_sensor_mean_s2  group_sensor_est_var_s1  \\\n0     a             -0.103881              0.018839                 0.007211   \n\n   group_sensor_est_var_s2  \n0                 0.004606  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>group</th>\n      <th>group_sensor_mean_s1</th>\n      <th>group_sensor_mean_s2</th>\n      <th>group_sensor_est_var_s1</th>\n      <th>group_sensor_est_var_s2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>a</td>\n      <td>-0.103881</td>\n      <td>0.018839</td>\n      <td>0.007211</td>\n      <td>0.004606</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = pandas.DataFrame({\n",
    "    'group': ['a'],\n",
    "    'group_sensor_mean_s1': [-0.103881],\n",
    "    'group_sensor_mean_s2': [0.018839],\n",
    "    'group_sensor_est_var_s1': [0.007211],\n",
    "    'group_sensor_est_var_s2': [0.004606],\n",
    "})\n",
    "\n",
    "b"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Coordinatized Data\n",
    "\n",
    "There are a number of ways to do this. Our preferred method is to use the [coordinatized data methodology](https://github.com/WinVector/data_algebra/blob/main/Examples/cdata/cdata_general_example.ipynb).\n",
    "\n",
    "In general the methodology works by specifying examples of the incoming and outgoing records, though it does have convenience methods for common tasks such as melting, pivoting, and un-pivoting.\n",
    "\n",
    "What we do is write down the incoming and outgoing record shapes."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "  sensor     group_sensor_mean     group_sensor_est_var\n0     s1  group_sensor_mean_s1  group_sensor_est_var_s1\n1     s2  group_sensor_mean_s2  group_sensor_est_var_s2",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sensor</th>\n      <th>group_sensor_mean</th>\n      <th>group_sensor_est_var</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>s1</td>\n      <td>group_sensor_mean_s1</td>\n      <td>group_sensor_est_var_s1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>s2</td>\n      <td>group_sensor_mean_s2</td>\n      <td>group_sensor_est_var_s2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_in = pandas.DataFrame({\n",
    "    'sensor': ['s1', 's2'],\n",
    "    'group_sensor_mean': ['group_sensor_mean_s1', 'group_sensor_mean_s2'],\n",
    "    'group_sensor_est_var': ['group_sensor_est_var_s1', 'group_sensor_est_var_s2'],\n",
    "})\n",
    "\n",
    "record_in\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notice these are just the example per-group records with specific values replaced by labels. These examples then specify the transform. The convention is: single row records don't need to be specified, and we draw out how multi row records work as follows."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "record_map = RecordMap(\n",
    "    blocks_in=RecordSpecification(\n",
    "        control_table=record_in,\n",
    "        record_keys=['group'],\n",
    "    ),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We confirm that the transform essentially takes `a` to `b`."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "  group  group_sensor_mean_s1  group_sensor_est_var_s1  group_sensor_mean_s2  \\\n0     a             -0.103881                 0.007211              0.018839   \n\n   group_sensor_est_var_s2  \n0                 0.004606  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>group</th>\n      <th>group_sensor_mean_s1</th>\n      <th>group_sensor_est_var_s1</th>\n      <th>group_sensor_mean_s2</th>\n      <th>group_sensor_est_var_s2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>a</td>\n      <td>-0.103881</td>\n      <td>0.007211</td>\n      <td>0.018839</td>\n      <td>0.004606</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_transform = record_map.transform(a)\n",
    "\n",
    "a_transform"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "assert data_algebra.test_util.equivalent_frames(a_transform, b)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We then add this step to our growing operator pipeline."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "  group  group_sensor_mean_s1  group_sensor_est_var_s1  group_sensor_mean_s2  \\\n0     a             -0.103881                 0.007211              0.018839   \n1     b              0.097989                 0.005530              0.470291   \n2     c              0.069197                 0.005891              0.017453   \n\n   group_sensor_est_var_s2  \n0                 0.004606  \n1                 0.006092  \n2                 0.006223  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>group</th>\n      <th>group_sensor_mean_s1</th>\n      <th>group_sensor_est_var_s1</th>\n      <th>group_sensor_mean_s2</th>\n      <th>group_sensor_est_var_s2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>a</td>\n      <td>-0.103881</td>\n      <td>0.007211</td>\n      <td>0.018839</td>\n      <td>0.004606</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>b</td>\n      <td>0.097989</td>\n      <td>0.005530</td>\n      <td>0.470291</td>\n      <td>0.006092</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>c</td>\n      <td>0.069197</td>\n      <td>0.005891</td>\n      <td>0.017453</td>\n      <td>0.006223</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ops = (\n",
    "    ops_var\n",
    "        .convert_records(record_map)\n",
    ")\n",
    "\n",
    "ops.transform(d)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notice instead of applying new operations to our data frame, we instead append new operations onto our existing operations pipeline `ops`.  This is the core of the data algebra: operating on pipelines to produce larger re-usable pipelines.\n",
    "\n",
    "We can now finish our task as a calculation using the available columns.\n",
    "\n",
    "## Putting it all Together"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "  group  mean_diff         t\n0     a  -0.122720 -1.128910\n1     b  -0.372302 -3.453425\n2     c   0.051744  0.470131",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>group</th>\n      <th>mean_diff</th>\n      <th>t</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>a</td>\n      <td>-0.122720</td>\n      <td>-1.128910</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>b</td>\n      <td>-0.372302</td>\n      <td>-3.453425</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>c</td>\n      <td>0.051744</td>\n      <td>0.470131</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ops = (\n",
    "    ops\n",
    "        .extend({'mean_diff': 'group_sensor_mean_s1 - group_sensor_mean_s2'})\n",
    "        .extend({'t': 'mean_diff / (group_sensor_est_var_s1 + group_sensor_est_var_s2).sqrt()'})\n",
    "        .drop_columns(['group_sensor_mean_s1', 'group_sensor_est_var_s1',\n",
    "                       'group_sensor_mean_s2', 'group_sensor_est_var_s2'])\n",
    "        .order_rows(['group'])\n",
    ")\n",
    "\n",
    "pandas_res = ops.transform(d)\n",
    "\n",
    "pandas_res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This result is close to the statistics package result.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "assert data_algebra.test_util.equivalent_frames(\n",
    "    pandas_res.loc[:, ['group', 't']],\n",
    "    group_stats.loc[:, ['group', 't']],\n",
    "    float_tol=0.01)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The new operations we showed here are:\n",
    "\n",
    "  * `drop_columns()`: remove columns. One could instead use `select_row()` to specify which columns are retained.\n",
    "  * `order_rows()`, which re-orders rows. Because data algebra is designed to work with SQL databases ordering (unless used to limit rows) only is safe as a last step in a pipeline.\n",
    "\n",
    "And we have our estimate: we reliably detect that the `b` is an unlikely measurement if there were no per-sensor difference in means for this group. We can re-apply the `ops` transform to any additional data frames that have the expected columns."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Databases\n",
    "\n",
    "An additional benefit of the data algebra is: the same operations can be applied to an arbitrary database (currently Google BigQuery, PostgreSQL, SQLite, Spark, and (partially) MySQL).\n",
    "\n",
    "To do this we build a model of the database connection."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "db_handle = data_algebra.BigQuery.example_handle()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We then, for purposes of illustration, insert our data into the database. In real applications the data is usually already in the database."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "(TableDescription(table_name=\"d\", column_names=[\"group\", \"value\", \"sensor\"]))"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_handle.insert_table(d, table_name='d', allow_overwrite=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "And now we can build a table that contains the result:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "db_handle.execute(f\"DROP TABLE IF EXISTS {db_handle.db_model.table_prefix}.res\")\n",
    "db_handle.execute(f\"CREATE TABLE {db_handle.db_model.table_prefix}.res AS \" + db_handle.to_sql(ops))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It is important to note, at this point all calculations are occurring in the database. No data is round tripping between the database and Python. With the right database, this can achieve a performance and scale that is beyond typical Python data frame tools and packages.\n",
    "\n",
    "We can, of course, look at the result."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "   mean_diff group         t\n0  -0.122720     a -1.128910\n1  -0.372302     b -3.453425\n2   0.051744     c  0.470131",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_diff</th>\n      <th>group</th>\n      <th>t</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.122720</td>\n      <td>a</td>\n      <td>-1.128910</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.372302</td>\n      <td>b</td>\n      <td>-3.453425</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.051744</td>\n      <td>c</td>\n      <td>0.470131</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_res = db_handle.read_query(f'SELECT * FROM {db_handle.db_model.table_prefix}.res')\n",
    "\n",
    "db_res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notice the results match the in-memory calculations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "assert data_algebra.test_util.equivalent_frames(pandas_res, db_res, float_tol=1e-3)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conclusion\n",
    "\n",
    "And that is how to translate a statistical calculation into a database using the data algebra. All one needs to start is a list of the allowed operations and expressions, we have links to such documentation [here](https://github.com/WinVector/data_algebra).\n",
    "\n",
    "The data algebra is optimized to allow one to build up a data processing pipeline piece by piece. This allows one to concentrate on solving sub-problems one at a time. The data algebra emphasizes as operators acting on each other through composition, processing data is the delayed end application.\n",
    "\n",
    "The resulting data algebra transform pipeline can be re-used on any number of data frames by the `.transform()` method and also used with different databases using the `.to_sql()` method. Data algebra pipelines can be saved using standard Python pickling procedures.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Appendices\n",
    "\n",
    "### The Entire Pipeline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\n",
      "    TableDescription(table_name=\"d\", column_names=[\"group\", \"value\", \"sensor\"])\n",
      "    .project(\n",
      "        {\n",
      "            \"group_sensor_var\": \"value.var()\",\n",
      "            \"group_sensor_mean\": \"value.mean()\",\n",
      "            \"group_sensor_n\": \"(1).sum()\",\n",
      "        },\n",
      "        group_by=[\"group\", \"sensor\"],\n",
      "    )\n",
      "    .extend({\"group_sensor_est_var\": \"group_sensor_var / group_sensor_n\"})\n",
      "    .convert_records(\n",
      "        data_algebra.cdata.RecordMap(\n",
      "            blocks_in=data_algebra.cdata.RecordSpecification(\n",
      "                record_keys=[\"group\"],\n",
      "                control_table=pd.DataFrame(\n",
      "                    {\n",
      "                        \"sensor\": [\"s1\", \"s2\"],\n",
      "                        \"group_sensor_mean\": [\n",
      "                            \"group_sensor_mean_s1\",\n",
      "                            \"group_sensor_mean_s2\",\n",
      "                        ],\n",
      "                        \"group_sensor_est_var\": [\n",
      "                            \"group_sensor_est_var_s1\",\n",
      "                            \"group_sensor_est_var_s2\",\n",
      "                        ],\n",
      "                    }\n",
      "                ),\n",
      "                control_table_keys=[\"sensor\"],\n",
      "            ),\n",
      "            blocks_out=None,\n",
      "        )\n",
      "    )\n",
      "    .extend({\"mean_diff\": \"group_sensor_mean_s1 - group_sensor_mean_s2\"})\n",
      "    .extend(\n",
      "        {\"t\": \"mean_diff / (group_sensor_est_var_s1 + group_sensor_est_var_s2).sqrt()\"}\n",
      "    )\n",
      "    .drop_columns(\n",
      "        [\n",
      "            \"group_sensor_mean_s1\",\n",
      "            \"group_sensor_est_var_s1\",\n",
      "            \"group_sensor_mean_s2\",\n",
      "            \"group_sensor_est_var_s2\",\n",
      "        ]\n",
      "    )\n",
      "    .order_rows([\"group\"])\n",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(ops)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The Generated SQL\n",
    "\n",
    "The generated SQL can be quite long, but remember we were able to build up our pipeline by composition. This allowed us to worry about each stage of operations separately.\n",
    "\n",
    "But, let's take a look at the produced SQL anyway."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- data_algebra SQL https://github.com/WinVector/data_algebra\n",
      "--  dialect: BigQueryModel\n",
      "--       string quote: \"\n",
      "--   identifier quote: `\n",
      "WITH\n",
      " `project_0` AS (\n",
      "  SELECT  -- .project({ 'group_sensor_var': 'value.var()', 'group_sensor_mean': 'value.mean()', 'group_sensor_n': '(1).sum()'}, group_by=['group', 'sensor'])\n",
      "   VAR_SAMP(`value`) AS `group_sensor_var` ,\n",
      "   AVG(`value`) AS `group_sensor_mean` ,\n",
      "   SUM(1) AS `group_sensor_n` ,\n",
      "   `group` ,\n",
      "   `sensor`\n",
      "  FROM\n",
      "   `data-algebra-test.test_1.d`\n",
      "  GROUP BY\n",
      "   `group` ,\n",
      "   `sensor`\n",
      " ) ,\n",
      " `extend_1` AS (\n",
      "  SELECT  -- .extend({ 'group_sensor_est_var': 'group_sensor_var / group_sensor_n'})\n",
      "   `group` ,\n",
      "   `sensor` ,\n",
      "   `group_sensor_var` ,\n",
      "   `group_sensor_mean` ,\n",
      "   `group_sensor_n` ,\n",
      "   `group_sensor_var` / `group_sensor_n` AS `group_sensor_est_var`\n",
      "  FROM\n",
      "   `project_0`\n",
      " ) ,\n",
      " `convert_records_blocks_in_2` AS (\n",
      "  -- convert records blocks in\n",
      "  SELECT\n",
      "     `group` AS `group`,\n",
      "     MAX(CASE WHEN  ( CAST(`sensor` AS STRING) = \"s1\" )  THEN `group_sensor_mean` ELSE NULL END) AS `group_sensor_mean_s1`,\n",
      "     MAX(CASE WHEN  ( CAST(`sensor` AS STRING) = \"s1\" )  THEN `group_sensor_est_var` ELSE NULL END) AS `group_sensor_est_var_s1`,\n",
      "     MAX(CASE WHEN  ( CAST(`sensor` AS STRING) = \"s2\" )  THEN `group_sensor_mean` ELSE NULL END) AS `group_sensor_mean_s2`,\n",
      "     MAX(CASE WHEN  ( CAST(`sensor` AS STRING) = \"s2\" )  THEN `group_sensor_est_var` ELSE NULL END) AS `group_sensor_est_var_s2`\n",
      "   FROM ( SELECT * FROM\n",
      "   `extend_1`\n",
      "    ) a\n",
      "   GROUP BY\n",
      "    `group`\n",
      "   ORDER BY\n",
      "    `group`\n",
      " ) ,\n",
      " `extend_3` AS (\n",
      "  SELECT  -- .extend({ 'mean_diff': 'group_sensor_mean_s1 - group_sensor_mean_s2'})\n",
      "   `group` ,\n",
      "   `group_sensor_est_var_s1` ,\n",
      "   `group_sensor_est_var_s2` ,\n",
      "   `group_sensor_mean_s1` - `group_sensor_mean_s2` AS `mean_diff`\n",
      "  FROM\n",
      "   `convert_records_blocks_in_2`\n",
      " ) ,\n",
      " `extend_4` AS (\n",
      "  SELECT  -- .extend({ 't': 'mean_diff / (group_sensor_est_var_s1 + group_sensor_est_var_s2).sqrt()'})\n",
      "   `mean_diff` ,\n",
      "   `group` ,\n",
      "   `mean_diff` / SQRT(`group_sensor_est_var_s1` + `group_sensor_est_var_s2`) AS `t`\n",
      "  FROM\n",
      "   `extend_3`\n",
      " )\n",
      "SELECT  -- .order_rows(['group'])\n",
      " *\n",
      "FROM\n",
      " `extend_4`\n",
      "ORDER BY\n",
      " `group`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(db_handle.to_sql(ops))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The data algebra emits different SQL for different SQL dialects. However, adapting to additional databases is a simple task."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Clean Up"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "db_handle.drop_table(\"d\")\n",
    "db_handle.drop_table(\"res\")\n",
    "db_handle.close()  # clean up"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}