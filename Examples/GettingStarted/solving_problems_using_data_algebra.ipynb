{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Using the data algebra for Statistics and Data Science\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This is an intermediate level example of using the [data algebra](https://github.com/WinVector/data_algebra)\n",
    "to translate a statistical method into an implementation that works both\n",
    "with Pandas and in databases.\n",
    "\n",
    "This example turns out to be fairly non-trivial, as it involves:\n",
    "\n",
    "  * Aggregating data at two different granularities.\n",
    "  * Combining the aggregations either through a \"pass through an extend\" or through \"join results\"\n",
    "    strategy.\n",
    "  * Re-shaping records to move from multi row records to single row records.\n",
    "\n",
    "This can be daunting. The guiding principle is: decompose into sub-problems, solve those,\n",
    "and then compose the pieces into a working solution. The data algebra supports this\n",
    "strategy as it is optimized to build up data processing pipelines from smaller pieces\n",
    "and is optimized for re-use and testing.\n",
    "\n",
    "### The problem\n",
    "\n",
    "We will demonstrate using the data algebra to solve a statistical problem: computing\n",
    "a difference in means in terms of a pooled standard deviation. What makes it a challenge is: we\n",
    "want to do this quickly per-group for possibly very many groups and re-scale by pooled standard\n",
    "deviations to get a measure of effect sizes.\n",
    "\n",
    "First we set up some example data in Python using Numpy and Pandas."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "import sqlite3\n",
    "import numpy\n",
    "import numpy.random\n",
    "import pandas\n",
    "\n",
    "from data_algebra.data_ops import *\n",
    "from data_algebra.cdata import *\n",
    "import data_algebra.SQLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "  group     value sensor\n0     a  0.051306     s2\n1     a  0.700005     s2\n2     a -1.022481     s2\n3     b  1.862029     s1\n4     c -1.173817     s2",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>group</th>\n      <th>value</th>\n      <th>sensor</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>a</td>\n      <td>0.051306</td>\n      <td>s2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>a</td>\n      <td>0.700005</td>\n      <td>s2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>a</td>\n      <td>-1.022481</td>\n      <td>s2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>b</td>\n      <td>1.862029</td>\n      <td>s1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>c</td>\n      <td>-1.173817</td>\n      <td>s2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build synthetic example data\n",
    "\n",
    "# seed the pseudo-random generator for repeatability\n",
    "numpy.random.seed(1999)\n",
    "\n",
    "# choose our simulated number of observations\n",
    "n_obs = 1000\n",
    "\n",
    "d = pandas.DataFrame({\n",
    "    'group': numpy.random.choice(['a', 'b', 'c'], size=n_obs, replace=True),\n",
    "    'value': numpy.random.normal(0, 1, size=n_obs),\n",
    "    'sensor': numpy.random.choice(['s1', 's2'], size=n_obs, replace=True),\n",
    "})\n",
    "# make the b group have an actual difference in means of s1 versus s2\n",
    "group_b_sensor_s2_rows = (d['group'] == 'b') & (d['sensor'] == 's2')\n",
    "d.loc[group_b_sensor_s2_rows, 'value'] = d.loc[group_b_sensor_s2_rows, 'value']  + 0.5\n",
    "\n",
    "d.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The data is synthetic. What is modeling is taking measurements from different groups using two different\n",
    "sensors.\n",
    "\n",
    "\n",
    "We want to see, for each group if the empirically observed\n",
    "difference in means in the values recorded by sensor `s1` and sensor `s2` are different in an interesting way.\n",
    "By our construction of the synthetic data there is a significant difference in group `b`, and not in any\n",
    "other group.\n",
    "\n",
    "This is essentially an [ANOVA](https://en.wikipedia.org/wiki/Analysis_of_variance)\n",
    "and [T-test](https://en.wikipedia.org/wiki/Student%27s_t-test) type of question, where we define interesting as\n",
    "the observed difference being rare under a null hypothesis such as the means and variance being shared\n",
    "between `s1` and `s2` sensors per group.\n",
    "\n",
    "Naturally there is statistical software that performs the above task well, but for our example let's pursue this\n",
    "by hand. Our quantity of interest is going to be: for each group we want to\n",
    "estimate `t = ((s1 estimate) - s2 estimate)) / (var(s1 estimate) + var(s2 estimate)).sqrt()`,\n",
    "where `(si estimte) = mean(si)`. This estimate is using the fact that, for independent processes\n",
    "variances are additive.\n",
    "\n",
    "When `|t|` is large\n",
    "(say 2 or 3), we consider the observed difference to be unlikely under the null hypothesis that the\n",
    "true means or expected values of `s1` and `s2` sensor are identical per group.\n",
    "The reasoning being under the null hypothesis\n",
    "(and under fairly mild additional conditions and with enough data), `t` with be\n",
    "nearly [Student-t distributed](https://en.wikipedia.org/wiki/Student%27s_t-distribution) where\n",
    "absolute values as large as 2 or 3 being somewhat rare.\n",
    "\n",
    "So let's estimate `t` using the data algebra.\n",
    "\n",
    "## The Solution\n",
    "\n",
    "The strategy is to break the calculation down into smaller solvable steps. The data algebra is essentially\n",
    "a coding of [Codd's relational algebra](https://en.wikipedia.org/wiki/Relational_algebra) in Python. This is just\n",
    "the thesis that if one learns a few primary data transforms, then many data processing tasks can\n",
    "be effectively written in terms of these operations. The operations are typically:\n",
    "\n",
    "\n",
    "   * Adding a column as function of other columns. That is for each row values are combined\n",
    "      to create a new value. This often called an extension.\n",
    "   * Computing an aggregation such as mean, max in one column controlled by a specification of\n",
    "     which rows are to be grouped together. This is typically called projection if we want exactly\n",
    "     one row result per group or a \"window function\" if we want one result row per input row.\n",
    "   * Joining rows from two data frames that match on particular key columns. This is a powerful\n",
    "     method of mapped lookup and cross-product formation.\n",
    "\n",
    "In terms of these operators we want new columns such as `mean(s1 values)`, `mean(s2 values)`, and so on, to be calculated\n",
    "per group. The organizing idea is:\n",
    "\n",
    "> Imagine some columns such that if these columns were already in your data frame, then the calculation\n",
    "> would be easy to finish. Then add these columns to your data frame.\n",
    "\n",
    "Let's do that using the data algebra.\n",
    "\n",
    "### Adding Some Columns\n",
    "\n",
    "First we specify the operations we want to perform. The wish we are trying to satisfy is: \"the calculation\n",
    "would be much easier we already knew the pooled standard deviations and group sizes\".\n",
    "This is an extend operation partitioned by\n",
    "our grouping column `group`.\n",
    "\n",
    "Our definition of operators is as follows. We start with `describe_table()` which\n",
    "build a description of the column structure of our data frame `d`.\n",
    "We then call `.extend()` on this object to specify new columns (`group_sd` and `group_size`)\n",
    "we want produced. The `partition_by` specifies which set of rows go into each calculation.\n",
    "We also add more steps to combine these columns to get the per-group variances.\n",
    "Notice the later steps don't use a partition to be specified, as we can\n",
    "safely calculate per row. The rule is: each extend is separated to use only values that\n",
    "are available before the step.\n",
    "\n",
    "This is easiest just to see this in action."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# define our operators\n",
    "ops = (\n",
    "    describe_table(d, table_name='d')\n",
    "        .extend(\n",
    "            {\n",
    "                'group_mean': 'value.mean()',\n",
    "                'group_size': '(1).sum()'\n",
    "            },\n",
    "            partition_by=['group'])\n",
    "        .extend({'sq_diff': '(value - group_mean)**2'})\n",
    "        .extend(\n",
    "            {'group_var': 'sq_diff.mean()'},\n",
    "            partition_by=['group'])\n",
    "        .extend({'group_var': 'group_var * group_size / (group_size - 1)'})  # adjust to sample variance\n",
    "        .drop_columns(['sq_diff'])\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Each extend can only refer to values that already exist, this is to prevent\n",
    "confusion as to which values are in which columns during calculation. The operations we used are:\n",
    "\n",
    "  * `extend()`: add new columns to current rows. This can work either without a partition, where each calculation\n",
    "     is performed among values in each row. Or this can work with a partition, where values are aggregated\n",
    "     across groups of rows, but still written into the original rows. In an `extend()` the calculation\n",
    "     is specified as a dictionary of new column values mapping to the quoted expressions to calculate the\n",
    "     values. The expression grammar is similar to Python/Numpy/Pandas, with a good number of methods\n",
    "     available.\n",
    "  *  `drop_columns()`: deletes columns we no longer want.\n",
    "\n",
    "The types of operators will be familiar to [dplyr]( https://CRAN.R-project.org/package=dplyr) users. However,\n",
    "they originally come from Codd, and this style of emphasis on composition was\n",
    "prototyped in [rqdatatable](https://CRAN.R-project.org/package=rqdatatable).\n",
    "\n",
    "Our working values look like the following if we apply the operations we have up to now."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "  group     value sensor  group_mean  group_size  group_var\n0     a  0.051306     s2   -0.032390         321   0.905921\n1     a  0.700005     s2   -0.032390         321   0.905921\n2     a -1.022481     s2   -0.032390         321   0.905921\n3     b  1.862029     s1    0.285289         324   0.973845\n4     c -1.173817     s2    0.041649         355   1.081075",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>group</th>\n      <th>value</th>\n      <th>sensor</th>\n      <th>group_mean</th>\n      <th>group_size</th>\n      <th>group_var</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>a</td>\n      <td>0.051306</td>\n      <td>s2</td>\n      <td>-0.032390</td>\n      <td>321</td>\n      <td>0.905921</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>a</td>\n      <td>0.700005</td>\n      <td>s2</td>\n      <td>-0.032390</td>\n      <td>321</td>\n      <td>0.905921</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>a</td>\n      <td>-1.022481</td>\n      <td>s2</td>\n      <td>-0.032390</td>\n      <td>321</td>\n      <td>0.905921</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>b</td>\n      <td>1.862029</td>\n      <td>s1</td>\n      <td>0.285289</td>\n      <td>324</td>\n      <td>0.973845</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>c</td>\n      <td>-1.173817</td>\n      <td>s2</td>\n      <td>0.041649</td>\n      <td>355</td>\n      <td>1.081075</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply our operators to our data frame d\n",
    "ops.transform(d).head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notice in the rows with `group == \"a\"` we see the same observed `group_var` (`0.905921`).\n",
    "\n",
    "The `transform()` implementation is modular and is intended to eventually support other\n",
    "realizations of Pandas style APIs.\n",
    "Prospects include Dask, datatable, RAPIDS; but we have not started development on these adapters.\n",
    "To support his prospect there is only one explicit reference to Pandas in the package, and\n",
    "that reference can be overridden by the user.\n",
    "\n",
    "### Adding Another Set of Columns\n",
    "\n",
    "We also want the per `group` *and* `sensor` means to compare.\n",
    "We can calculate this with a project, as we only want one output row for\n",
    "each combination of `group` *and* `sensor`.\n",
    "\n",
    "We continue our calculation as follows."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# define our operators\n",
    "ops = (\n",
    "    ops\n",
    "        .project(\n",
    "            {\n",
    "                'group_sensor_mean': 'value.mean()',\n",
    "                'group_sensor_size': '(1).sum()',\n",
    "                'group_size': 'group_size.mean()',  # pseudo aggregation, value is constant in each group\n",
    "                'group_var': 'group_var.mean()',    # pseudo aggregation, value is constant in each group\n",
    "             },\n",
    "            group_by=['group', 'sensor']\n",
    "            )\n",
    "        .extend({'group_sensor_est_var': 'group_var / group_sensor_size'})\n",
    "        .drop_columns(['group_sensor_size', 'group_size', 'group_var'])\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The new operation we used is `project()`.\n",
    "\n",
    "  * `project()` is a grouped operation where each group\n",
    "     of rows is replaced by a single row. The grouping columns are copied into the new row, so\n",
    "     they don't have to be specified. Any other columns must be created by calculations. The\n",
    "     \"pseudo aggregators\" are how we copy-out columns we wish to keep around.\n",
    "\n",
    "\n",
    "An alternative to\n",
    "the `extend()` then `project()` solution we showed here would be to perform two projects and\n",
    "then join the results back to together. We will illustrate this solution in an appendix.\n",
    "\n",
    "Notice instead of applying new operations to our data frame, we instead append new\n",
    "operations onto our existing operations pipeline `ops`.  This is the core of the data algebra:\n",
    "operating on pipelines to produce larger re-usable pipelines.\n",
    "\n",
    "We can examine our composite pipeline."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\n",
      "    TableDescription(table_name=\"d\", column_names=[\"group\", \"value\", \"sensor\"])\n",
      "    .extend(\n",
      "        {\"group_mean\": \"value.mean()\", \"group_size\": \"(1).sum()\"},\n",
      "        partition_by=[\"group\"],\n",
      "    )\n",
      "    .extend({\"sq_diff\": \"(value - group_mean) ** 2\"})\n",
      "    .extend({\"group_var\": \"sq_diff.mean()\"}, partition_by=[\"group\"])\n",
      "    .extend({\"group_var\": \"(group_var * group_size) / (group_size - 1)\"})\n",
      "    .drop_columns([\"sq_diff\"])\n",
      "    .project(\n",
      "        {\n",
      "            \"group_sensor_mean\": \"value.mean()\",\n",
      "            \"group_sensor_size\": \"(1).sum()\",\n",
      "            \"group_size\": \"group_size.mean()\",\n",
      "            \"group_var\": \"group_var.mean()\",\n",
      "        },\n",
      "        group_by=[\"group\", \"sensor\"],\n",
      "    )\n",
      "    .extend({\"group_sensor_est_var\": \"group_var / group_sensor_size\"})\n",
      "    .drop_columns([\"group_sensor_size\", \"group_size\", \"group_var\"])\n",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(str(ops))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "And we can apply this pipeline to our data.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "  group sensor  group_sensor_mean  group_sensor_est_var\n0     a     s1          -0.103881              0.006761\n1     a     s2           0.018839              0.004844\n2     b     s1           0.097989              0.006049\n3     b     s2           0.470291              0.005975\n4     c     s1           0.069197              0.006512\n5     c     s2           0.017453              0.005720",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>group</th>\n      <th>sensor</th>\n      <th>group_sensor_mean</th>\n      <th>group_sensor_est_var</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>a</td>\n      <td>s1</td>\n      <td>-0.103881</td>\n      <td>0.006761</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>a</td>\n      <td>s2</td>\n      <td>0.018839</td>\n      <td>0.004844</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>b</td>\n      <td>s1</td>\n      <td>0.097989</td>\n      <td>0.006049</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>b</td>\n      <td>s2</td>\n      <td>0.470291</td>\n      <td>0.005975</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>c</td>\n      <td>s1</td>\n      <td>0.069197</td>\n      <td>0.006512</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>c</td>\n      <td>s2</td>\n      <td>0.017453</td>\n      <td>0.005720</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ops.transform(d)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Combining Rows to Get Results\n",
    "\n",
    "We can now see the sensors seem to differ more in group `b` than in the other groups. Let's\n",
    "finish the calculation and quantify this. We now have the issue of needing values from specific pairs of\n",
    "rows. The simplest way to work around this is to get all the values we want into a single row and then work\n",
    "forward.\n",
    "\n",
    "What we mean is we wish to take a record that looks like the following."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "  group sensor  group_sensor_mean  group_sensor_est_var\n0     a     s1          -0.103881              0.006761\n1     a     s2           0.018839              0.004844",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>group</th>\n      <th>sensor</th>\n      <th>group_sensor_mean</th>\n      <th>group_sensor_est_var</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>a</td>\n      <td>s1</td>\n      <td>-0.103881</td>\n      <td>0.006761</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>a</td>\n      <td>s2</td>\n      <td>0.018839</td>\n      <td>0.004844</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pandas.DataFrame({\n",
    "    'group': ['a', 'a'],\n",
    "    'sensor': ['s1', 's2'],\n",
    "    'group_sensor_mean': [-0.103881, 0.018839],\n",
    "    'group_sensor_est_var': [0.006761, 0.004844],\n",
    "})\n",
    "\n",
    "a"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "And transform it into a single row such as the following."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "  group  group_sensor_mean_s1  group_sensor_mean_s2  group_sensor_est_var_s1  \\\n0     a             -0.103881              0.018839                 0.006761   \n\n   group_sensor_est_var_s2  \n0                 0.004844  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>group</th>\n      <th>group_sensor_mean_s1</th>\n      <th>group_sensor_mean_s2</th>\n      <th>group_sensor_est_var_s1</th>\n      <th>group_sensor_est_var_s2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>a</td>\n      <td>-0.103881</td>\n      <td>0.018839</td>\n      <td>0.006761</td>\n      <td>0.004844</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = pandas.DataFrame({\n",
    "    'group': ['a'],\n",
    "    'group_sensor_mean_s1': [-0.103881],\n",
    "    'group_sensor_mean_s2': [0.018839],\n",
    "    'group_sensor_est_var_s1': [0.006761],\n",
    "    'group_sensor_est_var_s2': [0.004844],\n",
    "})\n",
    "\n",
    "b"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Coordinatized Data\n",
    "\n",
    "There are a number of ways to do this. Our preferred method is to use the [coordinatized data\n",
    "methodology](https://github.com/WinVector/data_algebra/blob/main/Examples/cdata/cdata_general_example.ipynb).\n",
    "\n",
    "In general the methodology works by specifying examples of the incoming and outgoing records, though\n",
    "it does have convenience methods for common tasks such as melting, pivoting, and un-pivoting.\n",
    "\n",
    "What we do is write down the incoming and outgoing record shapes."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "  sensor     group_sensor_mean     group_sensor_est_var\n0     s1  group_sensor_mean_s1  group_sensor_est_var_s1\n1     s2  group_sensor_mean_s2  group_sensor_est_var_s2",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sensor</th>\n      <th>group_sensor_mean</th>\n      <th>group_sensor_est_var</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>s1</td>\n      <td>group_sensor_mean_s1</td>\n      <td>group_sensor_est_var_s1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>s2</td>\n      <td>group_sensor_mean_s2</td>\n      <td>group_sensor_est_var_s2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_in = pandas.DataFrame({\n",
    "    'sensor': ['s1', 's2'],\n",
    "    'group_sensor_mean': ['group_sensor_mean_s1', 'group_sensor_mean_s2'],\n",
    "    'group_sensor_est_var': ['group_sensor_est_var_s1', 'group_sensor_est_var_s2'],\n",
    "})\n",
    "\n",
    "record_in\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notice these are just the example per-group records with specific values replaced by labels. These\n",
    "examples then specify the transform. The convention is: single row records don't need to be specified, and\n",
    "we draw out how multi row records work as follows."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "\n",
    "record_map = RecordMap(\n",
    "    blocks_in=data_algebra.cdata.RecordSpecification(\n",
    "        control_table=record_in,\n",
    "        record_keys=['group'],\n",
    "    ),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "And the transform essentially takes `a` to `b`."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "  group  group_sensor_mean_s1  group_sensor_est_var_s1  group_sensor_mean_s2  \\\n0     a             -0.103881                 0.006761              0.018839   \n\n   group_sensor_est_var_s2  \n0                 0.004844  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>group</th>\n      <th>group_sensor_mean_s1</th>\n      <th>group_sensor_est_var_s1</th>\n      <th>group_sensor_mean_s2</th>\n      <th>group_sensor_est_var_s2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>a</td>\n      <td>-0.103881</td>\n      <td>0.006761</td>\n      <td>0.018839</td>\n      <td>0.004844</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_map.transform(a)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We then add this step to our growing operator pipeline."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "  group  group_sensor_mean_s1  group_sensor_est_var_s1  group_sensor_mean_s2  \\\n0     a             -0.103881                 0.006761              0.018839   \n1     b              0.097989                 0.006049              0.470291   \n2     c              0.069197                 0.006512              0.017453   \n\n   group_sensor_est_var_s2  \n0                 0.004844  \n1                 0.005975  \n2                 0.005720  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>group</th>\n      <th>group_sensor_mean_s1</th>\n      <th>group_sensor_est_var_s1</th>\n      <th>group_sensor_mean_s2</th>\n      <th>group_sensor_est_var_s2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>a</td>\n      <td>-0.103881</td>\n      <td>0.006761</td>\n      <td>0.018839</td>\n      <td>0.004844</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>b</td>\n      <td>0.097989</td>\n      <td>0.006049</td>\n      <td>0.470291</td>\n      <td>0.005975</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>c</td>\n      <td>0.069197</td>\n      <td>0.006512</td>\n      <td>0.017453</td>\n      <td>0.005720</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ops = (\n",
    "    ops\n",
    "        .convert_records(record_map)\n",
    ")\n",
    "\n",
    "ops.transform(d)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "And we then finish our calculation using the available columns.\n",
    "\n",
    "## Putting it all Together"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "  group  mean_diff         t\n0     a  -0.122720 -1.139176\n1     b  -0.372302 -3.395352\n2     c   0.051744  0.467844",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>group</th>\n      <th>mean_diff</th>\n      <th>t</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>a</td>\n      <td>-0.122720</td>\n      <td>-1.139176</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>b</td>\n      <td>-0.372302</td>\n      <td>-3.395352</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>c</td>\n      <td>0.051744</td>\n      <td>0.467844</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ops = (\n",
    "    ops\n",
    "        .extend({'mean_diff': 'group_sensor_mean_s1 - group_sensor_mean_s2'})\n",
    "        .extend({'t': 'mean_diff / (group_sensor_est_var_s1 + group_sensor_est_var_s2).sqrt()'})\n",
    "        .drop_columns(['group_sensor_mean_s1', 'group_sensor_est_var_s1',\n",
    "                       'group_sensor_mean_s2', 'group_sensor_est_var_s2'])\n",
    "        .order_rows(['group'])\n",
    ")\n",
    "\n",
    "ops.transform(d)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The new operations we showed here is 'order_rows()`, which re-orders rows. Because\n",
    "data algebra is designed to work with SQL databases ordering (unless used to limit rows)\n",
    "only is safe as a last step in a pipeline.\n",
    "\n",
    "And we have our estimate: we reliably detect that the `b` is an unlikely measurement\n",
    "if there were no per-sensor difference in means for this group. We can re-apply the `ops`\n",
    "transform to any additional data frames that have the expected columns."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Databases\n",
    "\n",
    "An additional benefit of the data algebra is: the same operations can be applied to an arbitrary database\n",
    "(currently Google BigQuery, PostgreSQL, MySQL, SQLite, and Spark).\n",
    "\n",
    "To do this we build a model of the database connection."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "sql_model = data_algebra.SQLite.SQLiteModel()\n",
    "conn = sqlite3.connect(\":memory:\")\n",
    "sql_model.prepare_connection(conn)\n",
    "db_handle = data_algebra.db_model.DBHandle(db_model=sql_model, conn=conn)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We then, for purposes of illustration, insert our data into the database. In real applications\n",
    "the data is usually already in the database."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "(TableDescription(table_name=\"d\", column_names=[\"group\", \"value\", \"sensor\"]))"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_handle.insert_table(d, table_name='d')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "And now we can build a table that contains the result:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "db_handle.execute(\"CREATE TABLE res AS \" + db_handle.to_sql(ops))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It is important to note, at this point all calculations are occurring in the database. No\n",
    "data is round tripping between the database and Python. With the right database, this can achieve a performance and\n",
    "scale that is beyond typical Python data frame tools and packages.\n",
    "\n",
    "We can, of course, look at the result."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "  group  mean_diff         t\n0     a  -0.122720 -1.139176\n1     b  -0.372302 -3.395352\n2     c   0.051744  0.467844",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>group</th>\n      <th>mean_diff</th>\n      <th>t</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>a</td>\n      <td>-0.122720</td>\n      <td>-1.139176</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>b</td>\n      <td>-0.372302</td>\n      <td>-3.395352</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>c</td>\n      <td>0.051744</td>\n      <td>0.467844</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_handle.read_query('SELECT * FROM res')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notice the results match the in-memory calculations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SQL\n",
    "\n",
    "The realized SQL can be quite long, but remember we were able to build up\n",
    "our pipeline by composition. This allowed us to worry about each stage of operations\n",
    "separately.\n",
    "\n",
    "But, let's take a look at the produced SQL."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- data_algebra SQL https://github.com/WinVector/data_algebra\n",
      "--  dialect: SQLiteModel\n",
      "--       string quote: '\n",
      "--   identifier quote: \"\n",
      "WITH\n",
      " \"convert_records_in_6\" AS (\n",
      "  SELECT  -- convert records\n",
      "   \"group_sensor_est_var_s2\" ,\n",
      "   \"group_sensor_mean_s2\" ,\n",
      "   \"group_sensor_est_var_s1\" ,\n",
      "   \"group\" ,\n",
      "   \"group_sensor_mean_s1\"\n",
      "  FROM\n",
      "  (\n",
      "  SELECT\n",
      " \"group\" AS \"group\",\n",
      " MAX(CASE WHEN  ( CAST(\"sensor\" AS VARCHAR) = 's1' )  THEN \"group_sensor_mean\" ELSE NULL END) AS \"group_sensor_mean_s1\",\n",
      " MAX(CASE WHEN  ( CAST(\"sensor\" AS VARCHAR) = 's1' )  THEN \"group_sensor_est_var\" ELSE NULL END) AS \"group_sensor_est_var_s1\",\n",
      " MAX(CASE WHEN  ( CAST(\"sensor\" AS VARCHAR) = 's2' )  THEN \"group_sensor_mean\" ELSE NULL END) AS \"group_sensor_mean_s2\",\n",
      " MAX(CASE WHEN  ( CAST(\"sensor\" AS VARCHAR) = 's2' )  THEN \"group_sensor_est_var\" ELSE NULL END) AS \"group_sensor_est_var_s2\"\n",
      "FROM (\n",
      "  SELECT  -- .extend({ 'group_sensor_est_var': 'group_var / group_sensor_size'})\n",
      " \"group\" ,\n",
      " \"sensor\" ,\n",
      " \"group_sensor_mean\" ,\n",
      " \"group_var\" / \"group_sensor_size\" AS \"group_sensor_est_var\"\n",
      "FROM\n",
      " (\n",
      " SELECT  -- .project({ 'group_sensor_mean': 'value.mean()', 'group_sensor_size': '(1).sum()', 'group_size': 'group_size.mean()', 'group_var': 'group_var.mean()'}, group_by=['group', 'sensor'])\n",
      "  \"sensor\" ,\n",
      "  SUM(1) AS \"group_sensor_size\" ,\n",
      "  AVG(\"group_var\") AS \"group_var\" ,\n",
      "  \"group\" ,\n",
      "  AVG(\"value\") AS \"group_sensor_mean\"\n",
      " FROM\n",
      "  (\n",
      "  SELECT  -- .extend({ 'group_var': '(group_var * group_size) / (group_size - 1)'})\n",
      "   (\"group_var\" * \"group_size\") / (\"group_size\" - 1) AS \"group_var\" ,\n",
      "   \"group\" ,\n",
      "   \"value\" ,\n",
      "   \"sensor\"\n",
      "  FROM\n",
      "   (\n",
      "   SELECT  -- .extend({ 'group_var': 'sq_diff.mean()'}, partition_by=['group'])\n",
      "    \"sensor\" ,\n",
      "    \"group_size\" ,\n",
      "    AVG(\"sq_diff\") OVER ( PARTITION BY \"group\"  )  AS \"group_var\" ,\n",
      "    \"group\" ,\n",
      "    \"value\"\n",
      "   FROM\n",
      "    (\n",
      "    SELECT  -- .extend({ 'sq_diff': '(value - group_mean) ** 2'})\n",
      "     POWER(\"value\" - \"group_mean\", 2) AS \"sq_diff\" ,\n",
      "     \"group\" ,\n",
      "     \"value\" ,\n",
      "     \"sensor\" ,\n",
      "     \"group_size\"\n",
      "    FROM\n",
      "     (\n",
      "     SELECT  -- .extend({ 'group_mean': 'value.mean()', 'group_size': '(1).sum()'}, partition_by=['group'])\n",
      "      AVG(\"value\") OVER ( PARTITION BY \"group\"  )  AS \"group_mean\" ,\n",
      "      \"group\" ,\n",
      "      \"value\" ,\n",
      "      \"sensor\" ,\n",
      "      SUM(1) OVER ( PARTITION BY \"group\"  )  AS \"group_size\"\n",
      "     FROM\n",
      "      \"d\"\n",
      "     ) \"extend_0\"\n",
      "    ) \"extend_1\"\n",
      "   ) \"extend_2\"\n",
      "  ) \"extend_3\"\n",
      " GROUP BY\n",
      "  \"group\" ,\n",
      "  \"sensor\"\n",
      " ) \"project_4\"\n",
      " ) a\n",
      " GROUP BY \"group\"\n",
      " ORDER BY \"group\"\n",
      "  ) \"convert_records_out_7\"\n",
      " ),\n",
      " \"extend_8\" AS (\n",
      "  SELECT  -- .extend({ 'mean_diff': 'group_sensor_mean_s1 - group_sensor_mean_s2'})\n",
      "   \"group_sensor_est_var_s2\" ,\n",
      "   \"group_sensor_est_var_s1\" ,\n",
      "   \"group_sensor_mean_s1\" - \"group_sensor_mean_s2\" AS \"mean_diff\" ,\n",
      "   \"group\"\n",
      "  FROM\n",
      "   \"convert_records_in_6\"\n",
      " ),\n",
      " \"extend_9\" AS (\n",
      "  SELECT  -- .extend({ 't': 'mean_diff / ((group_sensor_est_var_s1 + group_sensor_est_var_s2)).sqrt()'})\n",
      "   \"group\" ,\n",
      "   \"mean_diff\" ,\n",
      "   \"mean_diff\" / SQRT(\"group_sensor_est_var_s1\" + \"group_sensor_est_var_s2\") AS \"t\"\n",
      "  FROM\n",
      "   \"extend_8\"\n",
      " )\n",
      "SELECT  -- .order_rows(['group'])\n",
      " *\n",
      "FROM\n",
      " \"extend_9\"\n",
      "ORDER BY\n",
      " \"group\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(db_handle.to_sql(ops))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The data algebra emits different SQL for different SQL dialects. Currently, we are actively developing\n",
    "and testing on Google Big Query, PostgreSQL, MySQL, SQLite, and SparkSQL. However, adapting\n",
    "to additional databases is a simple task."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conclusion\n",
    "\n",
    "And that is how to translate a statistical calculation into a database using the data algebra.\n",
    "All one needs to start is a list of the allowed operations and expressions, we have\n",
    "links to such documentation [here](https://github.com/WinVector/data_algebra).\n",
    "\n",
    "The data algebra is optimized to allow one to build up a data processing pipeline piece by piece.\n",
    "This allows one to concentrate on solving sub-problems one at a time. The data algebra\n",
    "emphasizes as operators acting on each other through composition, processing data is the\n",
    "delayed end application.\n",
    "\n",
    "The resulting data algebra transform pipeline can be\n",
    "re-used on any number of data frames by the `.transform()` method and also used with different\n",
    "databases using the `.to_sql()` method. Data algebra pipelines can be saved using standard Python pickling\n",
    "procedures.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Appendices\n",
    "\n",
    "### The Entire Pipeline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\n",
      "    TableDescription(table_name=\"d\", column_names=[\"group\", \"value\", \"sensor\"])\n",
      "    .extend(\n",
      "        {\"group_mean\": \"value.mean()\", \"group_size\": \"(1).sum()\"},\n",
      "        partition_by=[\"group\"],\n",
      "    )\n",
      "    .extend({\"sq_diff\": \"(value - group_mean) ** 2\"})\n",
      "    .extend({\"group_var\": \"sq_diff.mean()\"}, partition_by=[\"group\"])\n",
      "    .extend({\"group_var\": \"(group_var * group_size) / (group_size - 1)\"})\n",
      "    .drop_columns([\"sq_diff\"])\n",
      "    .project(\n",
      "        {\n",
      "            \"group_sensor_mean\": \"value.mean()\",\n",
      "            \"group_sensor_size\": \"(1).sum()\",\n",
      "            \"group_size\": \"group_size.mean()\",\n",
      "            \"group_var\": \"group_var.mean()\",\n",
      "        },\n",
      "        group_by=[\"group\", \"sensor\"],\n",
      "    )\n",
      "    .extend({\"group_sensor_est_var\": \"group_var / group_sensor_size\"})\n",
      "    .drop_columns([\"group_sensor_size\", \"group_size\", \"group_var\"])\n",
      "    .convert_records(\n",
      "        data_algebra.cdata.RecordMap(\n",
      "            blocks_in=data_algebra.cdata.RecordSpecification(\n",
      "                record_keys=[\"group\"],\n",
      "                control_table=pd.DataFrame(\n",
      "                    {\n",
      "                        \"sensor\": [\"s1\", \"s2\"],\n",
      "                        \"group_sensor_mean\": [\n",
      "                            \"group_sensor_mean_s1\",\n",
      "                            \"group_sensor_mean_s2\",\n",
      "                        ],\n",
      "                        \"group_sensor_est_var\": [\n",
      "                            \"group_sensor_est_var_s1\",\n",
      "                            \"group_sensor_est_var_s2\",\n",
      "                        ],\n",
      "                    }\n",
      "                ),\n",
      "                control_table_keys=[\"sensor\"],\n",
      "            ),\n",
      "            blocks_out=None,\n",
      "        )\n",
      "    )\n",
      "    .extend({\"mean_diff\": \"group_sensor_mean_s1 - group_sensor_mean_s2\"})\n",
      "    .extend(\n",
      "        {\n",
      "            \"t\": \"mean_diff / ((group_sensor_est_var_s1 + group_sensor_est_var_s2)).sqrt()\"\n",
      "        }\n",
      "    )\n",
      "    .drop_columns(\n",
      "        [\n",
      "            \"group_sensor_mean_s1\",\n",
      "            \"group_sensor_est_var_s1\",\n",
      "            \"group_sensor_mean_s2\",\n",
      "            \"group_sensor_est_var_s2\",\n",
      "        ]\n",
      "    )\n",
      "    .order_rows([\"group\"])\n",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(ops)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The Join Based Solution\n",
    "\n",
    "Instead of chaining our partitioned `extend()`, and using pseudo-aggregators, we can\n",
    "solve the problem with two `project()` steps pulled together with `natural_join()`."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "ops_join = (\n",
    "    describe_table(d, table_name='d')\n",
    "        .extend({'group_mean': 'value.mean()'},\n",
    "            partition_by=['group'])\n",
    "        .extend({'sq_diff': '(value - group_mean)**2'})\n",
    "        .project(\n",
    "            {\n",
    "                'group_var': 'sq_diff.mean()',\n",
    "                'group_size': '(1).sum()',\n",
    "            },\n",
    "            group_by=['group'])\n",
    "        .extend({'group_var': 'group_var * group_size / (group_size - 1)'})\n",
    "        .natural_join(\n",
    "            b=describe_table(d, table_name='d')\n",
    "                .project(\n",
    "                    {\n",
    "                        'group_sensor_mean': 'value.mean()',\n",
    "                        'group_sensor_size': '(1).sum()',\n",
    "                    },\n",
    "                    group_by=['group', 'sensor']\n",
    "                    ),\n",
    "            by=['group'],\n",
    "            jointype='inner',\n",
    "            )\n",
    "        .extend({'group_sensor_est_var': 'group_var / group_sensor_size'})\n",
    "        .convert_records(record_map)\n",
    "        .extend({'mean_diff': 'group_sensor_mean_s1 - group_sensor_mean_s2'})\n",
    "        .extend({'t': 'mean_diff / (group_sensor_est_var_s1 + group_sensor_est_var_s2).sqrt()'})\n",
    "        .drop_columns(['group_sensor_mean_s1', 'group_sensor_est_var_s1',\n",
    "                       'group_sensor_mean_s2', 'group_sensor_est_var_s2'])\n",
    "        .order_rows(['group'])\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The join solution computes the required per-`['group']` summaries and per-`['group', 'sensor']` summaries\n",
    "and then assembles them together. This replaces the \"pass the first calculation through a partitioned\n",
    "extend\" strategy of the first solution. Notice our \"pipeline\" is actually a \"DAG\" (directed acyclic graph),\n",
    "as we can use the same table as inputs in multiple places.\n",
    "\n",
    "The new step here is the `natural_join()`.\n",
    "\n",
    "\n",
    "  * `natural_join()` is a wrapper for Codd's fundamental relational operator:\n",
    "    the join. A join takes two data frames and builds the cross product of every pair of rows (including\n",
    "    some implicit special \"missing\" or \"empty\" rows) and retains the set of rows\n",
    "    matching the join conditions. `natural_join()` adds some convenience, such as copying over\n",
    "    join key columns and coalescing values for other column name collisions.\n",
    "\n",
    "\n",
    "In our case the join matches all rows in our two projects, replicating rows from the result that is indexed only by\n",
    "`['group']` so that every row indexed by `['group', 'sensor']` gets a match.\n",
    "In our case the \"`by`\" and \"`jointype`\" arguments specify what set of rows to produce (or how to align results).\n",
    "\n",
    "Notice we get the same results both in Pandas and from a database.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "  group  mean_diff         t\n0     a  -0.122720 -1.139176\n1     b  -0.372302 -3.395352\n2     c   0.051744  0.467844",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>group</th>\n      <th>mean_diff</th>\n      <th>t</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>a</td>\n      <td>-0.122720</td>\n      <td>-1.139176</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>b</td>\n      <td>-0.372302</td>\n      <td>-3.395352</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>c</td>\n      <td>0.051744</td>\n      <td>0.467844</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ops_join.transform(d)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "  group  mean_diff         t\n0     a  -0.122720 -1.139176\n1     b  -0.372302 -3.395352\n2     c   0.051744  0.467844",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>group</th>\n      <th>mean_diff</th>\n      <th>t</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>a</td>\n      <td>-0.122720</td>\n      <td>-1.139176</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>b</td>\n      <td>-0.372302</td>\n      <td>-3.395352</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>c</td>\n      <td>0.051744</td>\n      <td>0.467844</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_handle.read_query(ops_join)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Clean Up"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "db_handle.close()  # clean up"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}