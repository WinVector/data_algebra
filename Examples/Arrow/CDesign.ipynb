{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2>Introduction</h2>\n",
    "\n",
    "I would like to talk about some of the design principles in the <a href=\"https://github.com/WinVector/data_algebra\"><code>data_algebra</code> package</a> (and also in its sibling <a href=\"https://github.com/WinVector/rquery\"><code>rquery</code> package</a>).\n",
    "\n",
    "<!--more--><p/>\n",
    "\n",
    "<h2>Background</h2>\n",
    "\n",
    "<h3>sklearn Pipeline</h3>\n",
    "\n",
    "A major influence on the <code>data_algebra</code> design is <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline\"><code>sklearn.pipeline.Pipeline</code></a>. <code>sklearn.pipeline.Pipeline</code> itself presumably become public with <a href=\"https://github.com/scikit-learn/scikit-learn/commit/b99c76550e3cbe8b57b1ea27b6eb88817a36cb53\">Edouard Duchesnay's Jul 27, 2010 commit: \"add pipeline\"</a>.\n",
    "\n",
    "<code>sklearn.pipeline.Pipeline</code> maintains a list of steps to be applied to data.  What is interesting is the steps are <em>not</em> functions. Steps are instead objects that implement both a <code>.transform()</code> and a <code>.fit()</code> method.\n",
    "\n",
    "<code>.transform()</code> typically accepts a data-frame type structure and returns a modified version.  Typical operations include adding a new derived column, selected columns, selected rows, and so on.\n",
    "\n",
    "From a transform-alone point of view the steps compose like functions.  For list <code>[s, t]</code> <code>transform(x)</code> is defined to as:\n",
    "\n",
    "<pre><code>   transform([s, t], x) = \n",
    "      t.transform(s.transform(x))</pre></code>\n",
    "\n",
    "The fit-perspective are where things get interesting.  <code>obj.fit(x)</code> changes the internal state of obj based on the value <code>x</code> and returns a reference to <code>obj</code>.  I.e. it learns from the data and stores this result as a side-effect in the object itself.  In <code>sklearn</code> it is common to assume a composite method called <code>.fit_transform()</code> defined as: \n",
    "<code><pre>   obj.fit_transform(x) := obj.fit(x).transform(x)</pre></code>\n",
    "(the \"<code>:=</code>\" denoting \"defined as\").\n",
    "\n",
    "Using <code>.fit_transform()</code> we can explain that in a <code>sklearn Pipeline</code> <code>.fit()</code> is naturally thought of as:\n",
    "<code><pre>   fit([s, t], x]) = \n",
    "      t.fit(s.fit_transform(x))</pre></code>\n",
    "\n",
    "My point is: <code>sklearn.pipeline.Pipeline</code> generalizes function composition (as we see with the <code>.transform()</code> methods) to something more powerful (the ability to both fit and to transform).  This becomes the natural way to store a sequence of parameterized or data-dependent data transform steps (such as centering, scaling, missing value imputation, and much more).\n",
    "\n",
    "A rigid mindset where \"function composition is the only form of composition\" would not easily allow the above effects. Instead the composition idea is list concatenation or a free group (essentially the graduate school way of saying \"list concatenation\").\n",
    "\n",
    "<h3>Fist class citizens</h3>\n",
    "\n",
    "We are going to try to design our tools to be \"<a href=\"https://en.wikipedia.org/wiki/First-class_citizen\">first class citizens</a>\" in the sense of Strachey:\n",
    "\n",
    "<blockquote>\n",
    "<strong>First and second class objects.</strong> In <code>ALGOL</code>, a real number may appear in an expression or be assigned to a variable, and either of them may appear as an actual parameter in a procedure call. A procedure, on the other hand, may only appear in another procedure call either as the operator (the most common case) or as one of the actual parameters. There are no other expressions involving procedures or whose results are procedures. Thus in a sense procedures in <code>ALGOL</code> are second class citizensâ€”they always have to appear in person and can never be represented by a variable or expression (except in the case of a formal parameter)...\n",
    "<p/>\n",
    "<a href=\"https://en.wikipedia.org/wiki/First-class_citizen\">Quoted in Wikipedia.\n",
    "Christopher Strachey, \"Fundamental Concepts in Programming Languages\" in Higher-Order and Symbolic Computation 13:11 (2000); though published in 2000, these are notes from lectures Strachey delivered in August, 1967</a>\n",
    "</blockquote>\n",
    "\n",
    "What we will draw out: is if our data transform steps are \"first class citizens\" we should expect to be able to store them in variables, compose them, examine them, and many other steps.  A function that we can only use or even re-use is not giving us as much as we expect from other types.  Or alternately, if functions don't give us everything we want, we may not want to use them as our only type or abstraction of data processing steps.\n",
    "  \n",
    "\n",
    "<h3>Composability</h3>\n",
    "\n",
    "Most people first encounter the mathematical concept of \"composability\" in terms of functions.  This can give the false impression that to work with composable design principles, one must shoe-horn the object of interest to be functions or some sort of augmented functions.\n",
    "\n",
    "This Procrustean view loses a lot of design opportunities.\n",
    "\n",
    "In mathematics composability is directly studied by the field called \"<a href=\"https://en.wikipedia.org/wiki/Category_theory\">Category Theory</a>.\" So it makes sense to see if category theory may have ideas, notations, tools, and results that may be of use.\n",
    "\n",
    "<h2>Category Theory</h2>\n",
    "\n",
    "A lot of the benefit of <a href=\"https://en.wikipedia.org/wiki/Category_theory\">category theory</a> is lost if every time we try to apply category theory (or even just use some of the notational conventions) we attempt to explain <em>all</em> of category theory as a first step.  So I will try to resist that urge here.  I will introduce the bits I am going to use here.\n",
    "\n",
    "Category theory routinely studies what are called \"arrows.\"  When treated abstractly an arrow has two associated objects called the \"domain\" and \"co-domain.\" The names are meant to be evocative of the \"domain\" (space of inputs) and \"co-domains\" (space of outputs) from the theory of functions.\n",
    "\n",
    "Category theory differs from function theory in that category theory is careful to keep separate the following two concepts: what arrows are and how arrows are composed.\n",
    "\n",
    "When using arrows to model a system we expect to be able to specify, with some degree of freedom:\n",
    "\n",
    "<ul>\n",
    "<li>Which arrow(s) are associated with a given domain and co-domain pair.</li>\n",
    "<li>How arrows compose.  For arrows <code>a</code> and <code>b</code> with <code>co-domain(b) = domain(a)</code> then: <code>a . b</code> denotes the composition in the category, and is itself a new arrow in the same category.  Composition is not allowed (or defined) when <code>co-domain(b) != domain(a)</code>.</li>\n",
    "<li>How arrows <a href=\"https://ncatlab.org/nlab/show/action\">act</a> on items.</li> \n",
    "</ul>\n",
    "\n",
    "An action is a mapping from arrows and items to items.  I.e. <code>action(arrow, item) = new_item</code>. For categories the items may or may not be related to the domain and co-domain. Not all categories have actions, but when they do have actions the action must be compatible with arrow composition.\n",
    "\n",
    "Good general references on category theory, include:\n",
    "\n",
    "<ul>\n",
    "    <li>Steve Awodey, <em>Category Theory, 2nd Edition</em>, Oxford University Press; 2010.</li>\n",
    "    <li>Emily Riehl, <em>Category Theory in Context</em>, Dover, 2016.</li>\n",
    "    <li>Saunders Mac Lane, <em>Categories for the Working Mathematician, 2nd Edition</em>, Springer, 1978.</li>\n",
    "</ul>\n",
    "\n",
    "\n",
    "Functions have a very ready category theory interpretation as arrows.  We can treat a function <code>f</code> as an arrow with domain equal to the set of values the function is defined for (also called the domain of the function) with co-domain equal to the image of the domain (also called the range of a function), or any set containing the range of the function.  In this formulation we define the arrow composition of <code>f</code> and <code>g</code> as <code>f . g</code> is defined to be the function such that for all <code>x</code> in domain <code>x</code> we have:\n",
    "<code><pre>   (f . g)(x) := f(g(x)) </pre></code>\n",
    "\n",
    "We will call the application of a function to a value as an example of an \"<a href=\"https://ncatlab.org/nlab/show/action\">action</a>.\" A function <code>f()</code> \"acts on its domain\" and <code>f(x)</code> is the action of <code>f</code> on <code>x</code>.  For functions we can define the action \"<code>apply</code>\" as:\n",
    "<code><pre>   apply(f, x) := f(x)</pre></code>\n",
    "\n",
    "The extra generalization power we get from moving away from functions to arbitrary arrows (that might not correspond to functions) comes from the following:\n",
    "\n",
    "<ul>\n",
    "<li>Arrow composition does <em>not</em> have to be function composition.</li>\n",
    "<li>Arrows can <a href=\"https://ncatlab.org/nlab/show/action\">act</a> on items that are <em>not</em> elements of their domain.</li>\n",
    "<li>Arrows have a notion of equality, but this notion <em>can differ</em> from having identical actions.  (Functions that have identical actions are usually considered to be identical by the <a href=\"https://en.wikipedia.org/wiki/Axiom_of_extensionality\">axiom of extensionality</a>.)</li>\n",
    "</ul>\n",
    "\n",
    "To be a category a few conditions must be met, including: the composition must be associative and we must have some identity arrows. By \"associative composition\" we mean, it must be the case that for arrows <code>a</code>,\n",
    "<code>b</code>, and <code>c</code> (with appropriate domains and co-domains):\n",
    "<code><pre>   (a . b) . c = a . (b . c) </pre></code>\n",
    "\n",
    "Our action must also associate with arrow composition.  That is we must have for values <code>x</code> we must have for covariant actions:\n",
    "<code><pre>   apply(a . b, x) = apply(a, apply(b, x))</pre></code>\n",
    "\n",
    "Or for contravariant actions:\n",
    "<code><pre>   apply(a . b, x) = apply(b, apply(a, x))</pre></code>\n",
    "\n",
    "\n",
    "The idea is: the arrow <code>a . b</code> must have an action equal to the actions of a and b composed as functions.\n",
    "\n",
    "Arrow composition and actions can differ from function composition and function application, but they must be at least somewhat similar in that they remain <a href=\"https://en.wikipedia.org/wiki/Associative_property\">associative</a>.\n",
    "\n",
    "<h2>Back to <code>sklearn.pipeline.Pipeline</code></h2>\n",
    "\n",
    "We now have enough notation to attempt a crude category theory description of <code>sklearn.pipeline.Pipeline</code>.\n",
    "\n",
    "Define our <code>sklearn.pipeline.Pipeline</code> category <code>P</code> as follows:\n",
    "\n",
    "<ul>\n",
    "<li>We have only one object called <code>0</code>. All arrows will have domain and co-domain equal to <code>0</code>, i.e.: we are not doing any interesting pre-condition checking in this category. </li>\n",
    "<li>The arrows of our category are lists of steps.  \n",
    "Steps are again <code>Python</code> objects\n",
    "that define <code>.transform()</code>, <code>.fit()</code>, and <code>.fit_transform()</code> methods.</li>\n",
    "<li>Composition <code>a1 . a2</code> is defined as list concatenation <code>a2 + a1</code>.  \"<code>+</code>\" being <code>Python</code>'s list concatenate in this case, and the order set to match <code>sklearn.pipeline.Pipeline</code> list order convention.</li>\n",
    "<li>We define an action called \"<code>transform_action</code>\" defined as:\n",
    "\n",
    "<code><pre>   transform_action([step1, step2, ..., stepk], x) := \n",
    "      stepk.transform(... step2.transform(step1.transform(x)) )</pre></code>\n",
    "</li>\n",
    "</ul>\n",
    "\n",
    "To see this is a category (and a category compatible action) we must check associativity of the composition (which in this case is list concatenation) and associativity of the action with respect to list concatenation.  \n",
    "\n",
    "We can also try to model the <code>.fit_transform()</code> methods.  We will not try to model the side-effect that <code>.fit_transform()</code> changes state of the arrows (to have the fit information in each step).  But we can at least define an action (with side effects) as follows:\n",
    "\n",
    "<ul>\n",
    "<li>We define an action called \"<code>fit_transform</code>\" defined as:\n",
    "\n",
    "<code><pre>   fit_transform_action([step1, step2, ..., stepk], x) := \n",
    "      stepk.fit_transform(... step2.fit_transform(step1.fit_transform(x)) )</pre></code>\n",
    "</li>\n",
    "</ul>\n",
    "\n",
    "To confirm this is roughly an action, we would want check is if the following equality holds or not:\n",
    "<code><pre>  fit_transform_action(a . b, x) =\n",
    "      fit_transform_action(b, fit_transform_action(a, x))\n",
    "   </pre></code>\n",
    "\n",
    "The above should follow by brute pushing notation around (assuming we have defined <code>fit_transform_action</code> correctly, and sufficiently characterized <code>.fit_transform()</code>).\n",
    "\n",
    "Notice we didn't define a \"<code>fit_action</code>\" action, as it isn't obvious that has a not obvious that has a nice associative realization. This an example of theory driving the design: <code>fit_transform()</code> may be more fundamental than, and thus preferred over, <code>fit()</code>, due to the easier to argue associativity of <code>fit_transform()</code>.\n",
    "\n",
    "The category theory concepts didn't so-much design <code>sklearn.pipeline.Pipeline</code>, but give us a set of criteria to evaluate <code>sklearn.pipeline.Pipeline</code> design.  We trust the category theory point of view is useful as it emphasizes associativity (which is a great proprety to have), and is routinely found to be a set of choices that work in complicated systems.  The feeling being: the design points category theory seems to suggest, turn out to be the one you want down the round.\n",
    "\n",
    "<h2>The <code>data_algebra</code></h2>\n",
    "\n",
    "<h3>What is the <code>data_algebra</code>?</h3>\n",
    "\n",
    "<ul>\n",
    "<li>\n",
    "    <a href=\"https://github.com/WinVector/data_algebra\"><code>data_algebra</code></a> is a package for building up complex data manipulation queries\n",
    " <code>data_algebra</code> queries are first class citizens in the Strachey sense (can be: passed as an argument, returned from a function, modified, assigned to a variable, printed, inspected, and traversed as a data structure).\n",
    "</li>\n",
    "<li>\n",
    " The operators are essentially those of the Codd relational algebra (select rows/columns, join, unionall, extend, project, and window functions).\n",
    "</li>\n",
    "<li>\n",
    "    Composition is left to right using method chaining.\n",
    "</li>\n",
    "<li>\n",
    "    Queries can be realized in <codd>SQL</code> (targeting <code>PostgeSQL</code> and <code>Spark</code>) or in <code>Pandas</code> (hoping to extend to <code>modin</code>, <code>RAPIDS</code>, and others).\n",
    "    </li>\n",
    "    <li>The <code>data_algebra</code> has an <a href=\"https://www.r-project.org\"><code>R</code></a> sibling package group\n",
    "        (<a href=\"https://github.com/WinVector/rquery\"><code>rquery</code></a>/<a href=\"https://github.com/WinVector/rqdatatable\"><code>rqdatatable</code></a>) similar to <a href=\"https://CRAN.R-project.org/package=dplyr\"><code>dplyr</code></a>.</li>\n",
    "</ul>\n",
    "\n",
    "An introduciton to the <code>data_algebra</code> can be found <a href=\"https://github.com/WinVector/data_algebra\">here</a>.\n",
    "\n",
    "We now have the terminology to concisely state a <code>data_algebra</code> design principle: use general concepts (such as category theory notation) to try and ensure <code>data_algebra</code> steps have a good description and are first class citizens (i.e. we can do a lot with them and to them).\n",
    "\n",
    "<h3>The naive functional view</h3>\n",
    "\n",
    "If we were to again take a mere functional view of the <a href=\"https://github.com/WinVector/data_algebra\"><code>data_algebra</code></a> we would say the <code>data_algebra</code> is a set of functions that operate on data.  They translate data frames to new data frames using <a href=\"https://en.wikipedia.org/wiki/Relational_algebra\">Codd]</a>-inspired operations. \n",
    "\n",
    "However, this is not correct.  <code>data_algebra</code> methods actually map data transforms to data tranforms.  We only apply them to data later.  However even this is a \"too functional view\" as the <code>data_algebra</code> compose a manner different than mere function composition.\n",
    "\n",
    "<h3>The categorical view</h3>\n",
    "\n",
    "The <code>data_algebra</code> can be mapped to a nice category.  The idea being something that can be easilly mapped to an orderly system, is it self likely an somewhat orderly system.\n",
    "\n",
    "Good references on the application of category theory to concrete systems (including databases) include:\n",
    "\n",
    "<ul>\n",
    "    <li>David I. Spivak, <em>Category Theory for the Sciences</em>; The MIT Press, 2014.</li>\n",
    "    <li>Brendan Fong, David I. Spivak, <em>An Invitation to Applied Category Theory: Seven Sketches in Compositionality</em>; Cambridge University Press, 2019.</li>\n",
    "</ul>\n",
    "\n",
    "\n",
    "Our <code>data_algebra</code> cateogry <code>D</code> is defined as follows.\n",
    "\n",
    "<ul>\n",
    "    <li>The objects of our category are single table <a href=\"https://en.wikipedia.org/wiki/Database_schema\">schemas</a>.</li>\n",
    "    <li>The arrows of our category are <code>data_algebra</code> operator chains.</li>\n",
    "    <li>Composition of arrows in our category is query commposition.  We will demonstarate query composition in a bit, but as a hint it is not function composition or list concatination.</li>\n",
    "</ul>\n",
    "\n",
    "Let's demonstrate the above with <code>Python</code> code.  The <code>data_algebra</code> allows for the specification of data transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x  y\n",
       "0  1  3\n",
       "1  2  4\n",
       "2  3  4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data_algebra.data_ops import *\n",
    "import pandas\n",
    "\n",
    "d = pandas.DataFrame({\n",
    "    'x': [1, 2, 3],\n",
    "    'y': [3, 4, 4],\n",
    "})\n",
    "\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To specify adding a new derived column <code>z</code> we would write code such as the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TableDescription(\n",
       " table_name='data_frame',\n",
       " column_names=[\n",
       "   'x', 'y']) .\\\n",
       "   extend({\n",
       "    'z': 'x.mean()'},\n",
       "   partition_by=['y'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td = describe_table(d)\n",
    "\n",
    "a = td.extend(\n",
    "    { 'z': 'x.mean()' },\n",
    "    partition_by=['y']\n",
    ")\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can let this transform act on data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x  y    z\n",
       "0  1  3  1.0\n",
       "1  2  4  2.5\n",
       "2  3  4  2.5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.transform(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can compose this transform with more operations to create a composite transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TableDescription(\n",
       " table_name='data_frame',\n",
       " column_names=[\n",
       "   'x', 'y']) .\\\n",
       "   extend({\n",
       "    'z': 'x.mean()'},\n",
       "   partition_by=['y']) .\\\n",
       "   extend({\n",
       "    'ratio': 'y / x'})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = a.extend({\n",
    "    'ratio': 'y / x'\n",
    "})\n",
    "\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a bonus we can also map the above transform to a <a href=\"https://en.wikipedia.org/wiki/SQL\"><code>SQL</code></a> query representing the same action in databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT \"x\",\n",
      "       \"y\",\n",
      "       \"z\",\n",
      "       \"y\" / \"x\" AS \"ratio\"\n",
      "FROM\n",
      "  (SELECT \"x\",\n",
      "          \"y\",\n",
      "          avg(\"x\") OVER (PARTITION BY \"y\") AS \"z\"\n",
      "   FROM (\"data_frame\") \"SQ_0\") \"SQ_1\"\n"
     ]
    }
   ],
   "source": [
    "from data_algebra.SQLite import SQLiteModel\n",
    "\n",
    "print(\n",
    "    b.to_sql(db_model=SQLiteModel(), pretty=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of this is the convenient interface we expect users will want.  However, if we asked that all operators specified their expected input schema (or their domain) we have the cateogry <code>D</code>.  We don't expect users to do such, but we have code supporting this style of notation to show that the <code>data_algebra</code> is in fact related to a nice category over schemas.\n",
    "\n",
    "Lets re-write the above queries as formal category arrows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      " 'data_frame':\n",
      "  [ x: <class 'numpy.int64'>, y: <class 'numpy.int64'> ]\n",
      "   ->\n",
      "  [ x, y, z ]\n",
      "]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from data_algebra.arrow import *\n",
    "\n",
    "a1 = DataOpArrow(a)\n",
    "\n",
    "print(str(a1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above is rendering the arrow as just its domain and co-domain. The doman and co-domains are just single-table schemas: lists of column names (possibly with column types).\n",
    "\n",
    "We can get a more detailed representation of the arrow as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataOpArrow(\n",
      " TableDescription(\n",
      " table_name='data_frame',\n",
      " column_names=[\n",
      "   'x', 'y']) .\\\n",
      "   extend({\n",
      "    'z': 'x.mean()'},\n",
      "   partition_by=['y']),\n",
      " free_table_key='data_frame')\n"
     ]
    }
   ],
   "source": [
    "print(a1.__repr__())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can examine the domain and co-domain directly.  Here we are using a common category theory trick: associating the object with the identity arrow of the object.  So what we are showing as domain and co-domains are actually identity arrows instead of objets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataOpArrow(\n",
       " TableDescription(\n",
       " table_name='',\n",
       " column_names=[\n",
       "   'x', 'y']),\n",
       " free_table_key='')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1.dom()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataOpArrow(\n",
       " TableDescription(\n",
       " table_name='',\n",
       " column_names=[\n",
       "   'x', 'y', 'z']),\n",
       " free_table_key='')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1.cod()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can write our second transform step as an arrow as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TableDescription(\n",
       " table_name='',\n",
       " column_names=[\n",
       "   'x', 'y', 'z']) .\\\n",
       "   extend({\n",
       "    'ratio': 'y / x'})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2 = a1.outgoing_table_description().extend({\n",
    "    'ratio': 'y / x'\n",
    "})\n",
    "\n",
    "a2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They payoff is, of course, arrow composition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "transform() got an unexpected keyword argument 'strict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-ca55918e064c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcomposite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma1\u001b[0m \u001b[0;34m>>\u001b[0m \u001b[0ma2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ai_academy_3_7/lib/python3.7/site-packages/data_algebra/arrow.py\u001b[0m in \u001b[0;36m__rshift__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__rshift__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# override self >> other\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__rrshift__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# override other >> self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: transform() got an unexpected keyword argument 'strict'"
     ]
    }
   ],
   "source": [
    "composite = a1 >> a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data_algebra.arrow.DataOpArrow"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
